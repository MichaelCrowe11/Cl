{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed6e120",
   "metadata": {},
   "source": [
    "# üöÄ CroweOS Unified Mycology Platform - Production Deployment Guide\n",
    "\n",
    "## Complete Docker Compose Microservices Architecture\n",
    "\n",
    "This comprehensive guide shows how to deploy the **Unified Mycology Platform** that combines:\n",
    "\n",
    "- **üîµ Crowe Logic AI Services** (Node.js/TypeScript) - New intelligent services\n",
    "- **üü¢ Crowe Vision Research Pipeline** (Python/Flask) - Existing analysis services\n",
    "\n",
    "### üéØ What You'll Build\n",
    "\n",
    "A production-ready microservices platform with:\n",
    "\n",
    "- ‚úÖ **11 Microservices** across 8 service categories\n",
    "- ‚úÖ **Complete Docker Compose Configuration** for instant deployment\n",
    "- ‚úÖ **API Gateway** (Nginx) routing all requests\n",
    "- ‚úÖ **PostgreSQL + Redis** for data persistence and caching  \n",
    "- ‚úÖ **Prometheus + Grafana** for monitoring and observability\n",
    "- ‚úÖ **Health Monitoring** and automated error recovery\n",
    "- ‚úÖ **Horizontal Scaling** ready for production workloads\n",
    "\n",
    "### üèóÔ∏è Architecture Overview\n",
    "\n",
    "```\n",
    "Frontend (Next.js) ‚Üí API Gateway (Nginx) ‚Üí Microservices\n",
    "                                        ‚îú‚îÄ‚îÄ Chat AI (Node.js)\n",
    "                                        ‚îú‚îÄ‚îÄ Computer Vision (Python)\n",
    "                                        ‚îú‚îÄ‚îÄ Bioactivity ML (Python)\n",
    "                                        ‚îú‚îÄ‚îÄ Literature Search (Python)\n",
    "                                        ‚îú‚îÄ‚îÄ Batch Processing (Python)\n",
    "                                        ‚îú‚îÄ‚îÄ Authentication (Python)\n",
    "                                        ‚îú‚îÄ‚îÄ Payment Processing (Python)\n",
    "                                        ‚îú‚îÄ‚îÄ Health Monitoring (Node.js)\n",
    "                                        ‚îú‚îÄ‚îÄ Notifications (Node.js)\n",
    "                                        ‚îú‚îÄ‚îÄ Batch Tracking (Node.js)\n",
    "                                        ‚îî‚îÄ‚îÄ Export & Reporting (Python)\n",
    "```\n",
    "\n",
    "### üîÑ Integration Benefits\n",
    "\n",
    "- **Unified Experience**: Single interface for all mycology research needs\n",
    "- **Technology Flexibility**: Node.js and Python services working together\n",
    "- **Scalable Architecture**: Independent scaling of each service\n",
    "- **Complete Workflow**: Image analysis ‚Üí AI insights ‚Üí Scientific reports\n",
    "- **Production Ready**: Health monitoring, error handling, observability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997faaa",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Prerequisites\n",
    "\n",
    "### üìã Prerequisites Checklist\n",
    "\n",
    "Before starting, ensure you have:\n",
    "\n",
    "- ‚úÖ **Docker** installed (version 20.10+)\n",
    "- ‚úÖ **Docker Compose** installed (version 2.0+)\n",
    "- ‚úÖ **Git** for cloning repositories\n",
    "- ‚úÖ **8GB+ RAM** for all services\n",
    "- ‚úÖ **API Keys** (OpenAI, Anthropic, iNaturalist, GBIF)\n",
    "- ‚úÖ **Domain name** (optional, for production SSL)\n",
    "\n",
    "### üèóÔ∏è Project Directory Structure\n",
    "\n",
    "Create the unified platform directory structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8936806b",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# Create unified mycology platform directory structure\n",
    "\n",
    "echo \"üèóÔ∏è Creating Unified Mycology Platform Directory Structure...\"\n",
    "\n",
    "# Create main project directory\n",
    "mkdir -p unified-mycology-platform\n",
    "cd unified-mycology-platform\n",
    "\n",
    "# Create service directories\n",
    "echo \"üìÅ Creating service directories...\"\n",
    "\n",
    "# New Node.js services (Crowe Logic AI)\n",
    "mkdir -p enhanced-chat-ai-service/{src,tests,docker}\n",
    "mkdir -p health-monitoring-service/{src,tests,docker}\n",
    "mkdir -p notification-service/{src,tests,docker}\n",
    "mkdir -p batch-tracking-service/{src,tests,docker}\n",
    "\n",
    "# Existing Python services (Crowe Vision Research Pipeline)\n",
    "mkdir -p computer-vision-service/{models,data,tests}\n",
    "mkdir -p bioactivity-service/{models,data,tests}\n",
    "mkdir -p literature-service/{cache,tests}\n",
    "mkdir -p batch-processing-service/{workers,tests}\n",
    "mkdir -p auth-service/{tests}\n",
    "mkdir -p payment-service/{tests}\n",
    "mkdir -p export-service/{templates,exports,tests}\n",
    "\n",
    "# Frontend\n",
    "mkdir -p frontend/{components,pages,api,public}\n",
    "\n",
    "# Configuration directories\n",
    "mkdir -p config/{nginx,prometheus,grafana,ssl}\n",
    "mkdir -p scripts/{deployment,monitoring,backup}\n",
    "mkdir -p data/{postgres,redis,logs}\n",
    "\n",
    "# Create essential configuration files\n",
    "touch docker-compose.yml\n",
    "touch docker-compose.override.yml\n",
    "touch .env\n",
    "touch .env.example\n",
    "touch nginx.conf\n",
    "touch init-databases.sh\n",
    "\n",
    "echo \"‚úÖ Directory structure created successfully!\"\n",
    "echo \"üìÅ Project structure:\"\n",
    "tree -d -L 2\n",
    "\n",
    "echo \"üîë Next steps:\"\n",
    "echo \"1. Copy your existing MycologyResearchPipeline services\"\n",
    "echo \"2. Configure environment variables in .env\"\n",
    "echo \"3. Set up Docker Compose configuration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f11e5b",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "# .env.example - Environment Variables Template\n",
    "# Copy this to .env and fill in your actual values\n",
    "\n",
    "# ================================\n",
    "# API Keys (Required)\n",
    "# ================================\n",
    "OPENAI_API_KEY=sk-your-openai-key-here\n",
    "ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\n",
    "INATURALIST_API_KEY=your-inaturalist-key-here\n",
    "GBIF_API_KEY=your-gbif-key-here\n",
    "\n",
    "# ================================\n",
    "# Payment Processing (Stripe)\n",
    "# ================================\n",
    "STRIPE_PUBLIC_KEY=pk_test_your-stripe-public-key\n",
    "STRIPE_SECRET_KEY=sk_test_your-stripe-secret-key\n",
    "STRIPE_WEBHOOK_SECRET=whsec_your-webhook-secret\n",
    "\n",
    "# ================================\n",
    "# Authentication & Security\n",
    "# ================================\n",
    "JWT_SECRET_KEY=your-super-secret-jwt-key-at-least-32-chars\n",
    "BCRYPT_ROUNDS=12\n",
    "SESSION_SECRET=your-session-secret-key\n",
    "\n",
    "# ================================\n",
    "# Email Configuration (SMTP)\n",
    "# ================================\n",
    "SMTP_HOST=smtp.gmail.com\n",
    "SMTP_PORT=587\n",
    "SMTP_USER=your-email@gmail.com\n",
    "SMTP_PASS=your-app-password\n",
    "SMTP_FROM=noreply@yourdomain.com\n",
    "\n",
    "# ================================\n",
    "# Database Configuration\n",
    "# ================================\n",
    "POSTGRES_USER=postgres\n",
    "POSTGRES_PASSWORD=secure-postgres-password\n",
    "POSTGRES_HOST=postgres\n",
    "POSTGRES_PORT=5432\n",
    "POSTGRES_DB=mycology_platform\n",
    "\n",
    "# Individual database URLs (auto-generated)\n",
    "DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/\n",
    "COMPUTER_VISION_DB_URL=${DATABASE_URL}computer_vision\n",
    "BIOACTIVITY_DB_URL=${DATABASE_URL}bioactivity\n",
    "LITERATURE_DB_URL=${DATABASE_URL}literature\n",
    "BATCH_PROCESSING_DB_URL=${DATABASE_URL}batch_processing\n",
    "NOTIFICATIONS_DB_URL=${DATABASE_URL}notifications\n",
    "BATCH_TRACKING_DB_URL=${DATABASE_URL}batch_tracking\n",
    "AUTH_DB_URL=${DATABASE_URL}auth\n",
    "PAYMENTS_DB_URL=${DATABASE_URL}payments\n",
    "EXPORTS_DB_URL=${DATABASE_URL}exports\n",
    "\n",
    "# ================================\n",
    "# Redis Configuration\n",
    "# ================================\n",
    "REDIS_PASSWORD=secure-redis-password\n",
    "REDIS_HOST=redis\n",
    "REDIS_PORT=6379\n",
    "REDIS_URL=redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}\n",
    "\n",
    "# ================================\n",
    "# Service Configuration\n",
    "# ================================\n",
    "NODE_ENV=production\n",
    "FLASK_ENV=production\n",
    "DEBUG=false\n",
    "LOG_LEVEL=info\n",
    "\n",
    "# ================================\n",
    "# Monitoring & Observability\n",
    "# ================================\n",
    "GRAFANA_ADMIN_PASSWORD=secure-grafana-password\n",
    "PROMETHEUS_RETENTION=15d\n",
    "METRICS_INTERVAL=30s\n",
    "\n",
    "# ================================\n",
    "# External Service URLs\n",
    "# ================================\n",
    "FRONTEND_URL=http://localhost:3100\n",
    "API_GATEWAY_URL=http://localhost\n",
    "HEALTH_DASHBOARD_URL=http://localhost:3001\n",
    "\n",
    "# ================================\n",
    "# File Storage\n",
    "# ================================\n",
    "UPLOAD_MAX_SIZE=10MB\n",
    "STORAGE_PATH=/app/storage\n",
    "EXPORT_PATH=/app/exports\n",
    "MODEL_PATH=/app/models\n",
    "\n",
    "# ================================\n",
    "# SSL Configuration (Production)\n",
    "# ================================\n",
    "SSL_ENABLED=false\n",
    "SSL_CERT_PATH=/etc/ssl/certs/cert.pem\n",
    "SSL_KEY_PATH=/etc/ssl/private/key.pem\n",
    "\n",
    "echo \"üìù Copy .env.example to .env and configure your values\"\n",
    "echo \"üîê Never commit .env to version control!\"\n",
    "echo \"üí° Use strong passwords for production deployment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9afd03",
   "metadata": {},
   "source": [
    "## 2. Docker Compose Configuration\n",
    "\n",
    "### üê≥ Complete Production Docker Compose Setup\n",
    "\n",
    "The main `docker-compose.yml` orchestrates all services, databases, and monitoring tools for the unified platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a108f6f",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "# docker-compose.yml - Unified Mycology Platform Production Configuration\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  # API Gateway (Nginx)\n",
    "  api-gateway:\n",
    "    image: nginx:alpine\n",
    "    ports:\n",
    "      - \"80:80\"\n",
    "      - \"443:443\"\n",
    "    volumes:\n",
    "      - ./nginx.conf:/etc/nginx/nginx.conf\n",
    "      - ./config/ssl:/etc/ssl:ro\n",
    "    depends_on:\n",
    "      - chat-ai-service\n",
    "      - computer-vision-service\n",
    "      - bioactivity-service\n",
    "      - literature-service\n",
    "      - health-monitoring\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Core AI Services (Node.js/TypeScript)\n",
    "  chat-ai-service:\n",
    "    build:\n",
    "      context: ./enhanced-chat-ai-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    environment:\n",
    "      - NODE_ENV=production\n",
    "      - PORT=3000\n",
    "      - OPENAI_API_KEY=${OPENAI_API_KEY}\n",
    "      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}\n",
    "      - COMPUTER_VISION_SERVICE=http://computer-vision-service:5001\n",
    "      - BIOACTIVITY_SERVICE=http://bioactivity-service:5002\n",
    "      - LITERATURE_SERVICE=http://literature-service:5003\n",
    "      - NOTIFICATION_SERVICE=http://notification-service:3002\n",
    "      - DATABASE_URL=${DATABASE_URL}chat_ai\n",
    "      - REDIS_URL=${REDIS_URL}\n",
    "      - JWT_SECRET=${JWT_SECRET_KEY}\n",
    "    depends_on:\n",
    "      - postgres\n",
    "      - redis\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Computer Vision Service (Python/Flask) - From Research Pipeline\n",
    "  computer-vision-service:\n",
    "    build:\n",
    "      context: ./computer-vision-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"5001:5001\"\n",
    "    environment:\n",
    "      - FLASK_ENV=production\n",
    "      - PORT=5001\n",
    "      - DATABASE_URL=${COMPUTER_VISION_DB_URL}\n",
    "      - REDIS_URL=${REDIS_URL}\n",
    "      - CHAT_AI_SERVICE_URL=http://chat-ai-service:3000\n",
    "      - NOTIFICATION_SERVICE_URL=http://notification-service:3002\n",
    "      - BATCH_TRACKING_SERVICE_URL=http://batch-tracking-service:3003\n",
    "      - MODEL_PATH=/app/models\n",
    "    volumes:\n",
    "      - cv_models:/app/models\n",
    "      - analysis_data:/app/data\n",
    "    depends_on:\n",
    "      - postgres\n",
    "      - redis\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:5001/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 4G\n",
    "          cpus: '2'\n",
    "        reservations:\n",
    "          memory: 2G\n",
    "          cpus: '1'\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Bioactivity ML Service (Python/Flask)\n",
    "  bioactivity-service:\n",
    "    build:\n",
    "      context: ./bioactivity-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"5002:5002\"\n",
    "    environment:\n",
    "      - FLASK_ENV=production\n",
    "      - PORT=5002\n",
    "      - DATABASE_URL=${BIOACTIVITY_DB_URL}\n",
    "      - ML_MODEL_PATH=/app/models/bioactivity_model.pkl\n",
    "      - DATASET_PATH=/app/data\n",
    "    volumes:\n",
    "      - bioactivity_models:/app/models\n",
    "      - bioactivity_data:/app/data\n",
    "    depends_on:\n",
    "      - postgres\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 8G\n",
    "          cpus: '4'\n",
    "        reservations:\n",
    "          memory: 4G\n",
    "          cpus: '2'\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Literature Search Service (Python/Flask)\n",
    "  literature-service:\n",
    "    build:\n",
    "      context: ./literature-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"5003:5003\"\n",
    "    environment:\n",
    "      - FLASK_ENV=production\n",
    "      - PORT=5003\n",
    "      - DATABASE_URL=${LITERATURE_DB_URL}\n",
    "      - INATURALIST_API_KEY=${INATURALIST_API_KEY}\n",
    "      - GBIF_API_KEY=${GBIF_API_KEY}\n",
    "      - REDIS_URL=${REDIS_URL}\n",
    "    depends_on:\n",
    "      - postgres\n",
    "      - redis\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Batch Processing Service (Python/Flask)\n",
    "  batch-processing-service:\n",
    "    build:\n",
    "      context: ./batch-processing-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"5004:5004\"\n",
    "    environment:\n",
    "      - FLASK_ENV=production\n",
    "      - PORT=5004\n",
    "      - DATABASE_URL=${BATCH_PROCESSING_DB_URL}\n",
    "      - REDIS_URL=${REDIS_URL}\n",
    "      - COMPUTER_VISION_SERVICE=http://computer-vision-service:5001\n",
    "      - CELERY_BROKER_URL=${REDIS_URL}\n",
    "      - CELERY_RESULT_BACKEND=${REDIS_URL}\n",
    "    depends_on:\n",
    "      - postgres\n",
    "      - redis\n",
    "      - computer-vision-service\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Supporting Services\n",
    "  health-monitoring:\n",
    "    build:\n",
    "      context: ./health-monitoring-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"3001:3001\"\n",
    "    environment:\n",
    "      - NODE_ENV=production\n",
    "      - PORT=3001\n",
    "      - SERVICES_TO_MONITOR=chat-ai-service:3000,computer-vision-service:5001,bioactivity-service:5002,literature-service:5003\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  notification-service:\n",
    "    build:\n",
    "      context: ./notification-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"3002:3002\"\n",
    "    environment:\n",
    "      - NODE_ENV=production\n",
    "      - PORT=3002\n",
    "      - DATABASE_URL=${NOTIFICATIONS_DB_URL}\n",
    "      - REDIS_URL=${REDIS_URL}\n",
    "      - SMTP_HOST=${SMTP_HOST}\n",
    "      - SMTP_USER=${SMTP_USER}\n",
    "      - SMTP_PASS=${SMTP_PASS}\n",
    "    depends_on:\n",
    "      - postgres\n",
    "      - redis\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  batch-tracking-service:\n",
    "    build:\n",
    "      context: ./batch-tracking-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"3003:3003\"\n",
    "    environment:\n",
    "      - NODE_ENV=production\n",
    "      - PORT=3003\n",
    "      - DATABASE_URL=${BATCH_TRACKING_DB_URL}\n",
    "      - COMPUTER_VISION_SERVICE=http://computer-vision-service:5001\n",
    "      - NOTIFICATION_SERVICE=http://notification-service:3002\n",
    "    depends_on:\n",
    "      - postgres\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Authentication Service (Python/Flask) - From Research Pipeline\n",
    "  auth-service:\n",
    "    build:\n",
    "      context: ./auth-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"5005:5005\"\n",
    "    environment:\n",
    "      - FLASK_ENV=production\n",
    "      - PORT=5005\n",
    "      - DATABASE_URL=${AUTH_DB_URL}\n",
    "      - JWT_SECRET_KEY=${JWT_SECRET_KEY}\n",
    "      - REDIS_URL=${REDIS_URL}\n",
    "      - BCRYPT_ROUNDS=${BCRYPT_ROUNDS}\n",
    "    depends_on:\n",
    "      - postgres\n",
    "      - redis\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Payment Service (Python/Flask) - From Research Pipeline\n",
    "  payment-service:\n",
    "    build:\n",
    "      context: ./payment-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"5006:5006\"\n",
    "    environment:\n",
    "      - FLASK_ENV=production\n",
    "      - PORT=5006\n",
    "      - DATABASE_URL=${PAYMENTS_DB_URL}\n",
    "      - STRIPE_PUBLIC_KEY=${STRIPE_PUBLIC_KEY}\n",
    "      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}\n",
    "      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}\n",
    "    depends_on:\n",
    "      - postgres\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Export & Reporting Service (Python/Flask)\n",
    "  export-service:\n",
    "    build:\n",
    "      context: ./export-service\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"5007:5007\"\n",
    "    environment:\n",
    "      - FLASK_ENV=production\n",
    "      - PORT=5007\n",
    "      - DATABASE_URL=${EXPORTS_DB_URL}\n",
    "      - COMPUTER_VISION_SERVICE=http://computer-vision-service:5001\n",
    "      - BIOACTIVITY_SERVICE=http://bioactivity-service:5002\n",
    "      - LITERATURE_SERVICE=http://literature-service:5003\n",
    "    volumes:\n",
    "      - export_files:/app/exports\n",
    "      - report_templates:/app/templates:ro\n",
    "    depends_on:\n",
    "      - postgres\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Frontend Application (Next.js)\n",
    "  frontend:\n",
    "    build:\n",
    "      context: ./frontend\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"3100:3000\"\n",
    "    environment:\n",
    "      - NEXT_PUBLIC_API_URL=${API_GATEWAY_URL}/api\n",
    "      - NEXT_PUBLIC_HEALTH_SERVICE_URL=${HEALTH_DASHBOARD_URL}\n",
    "      - NODE_ENV=production\n",
    "    depends_on:\n",
    "      - api-gateway\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Database Services\n",
    "  postgres:\n",
    "    image: postgres:15-alpine\n",
    "    environment:\n",
    "      - POSTGRES_USER=${POSTGRES_USER}\n",
    "      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\n",
    "      - POSTGRES_DB=${POSTGRES_DB}\n",
    "    volumes:\n",
    "      - postgres_data:/var/lib/postgresql/data\n",
    "      - ./init-databases.sh:/docker-entrypoint-initdb.d/init-databases.sh:ro\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 5\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"redis-cli\", \"--raw\", \"incr\", \"ping\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 5\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Background Workers\n",
    "  celery-worker:\n",
    "    build:\n",
    "      context: ./batch-processing-service\n",
    "      dockerfile: Dockerfile\n",
    "    command: celery -A app.celery worker --loglevel=info --concurrency=4\n",
    "    environment:\n",
    "      - FLASK_ENV=production\n",
    "      - DATABASE_URL=${BATCH_PROCESSING_DB_URL}\n",
    "      - REDIS_URL=${REDIS_URL}\n",
    "      - CELERY_BROKER_URL=${REDIS_URL}\n",
    "      - CELERY_RESULT_BACKEND=${REDIS_URL}\n",
    "      - COMPUTER_VISION_SERVICE=http://computer-vision-service:5001\n",
    "    depends_on:\n",
    "      - postgres\n",
    "      - redis\n",
    "      - batch-processing-service\n",
    "    deploy:\n",
    "      replicas: 2\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  # Monitoring & Observability\n",
    "  prometheus:\n",
    "    image: prom/prometheus:latest\n",
    "    ports:\n",
    "      - \"9090:9090\"\n",
    "    volumes:\n",
    "      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro\n",
    "      - prometheus_data:/prometheus\n",
    "    command:\n",
    "      - '--config.file=/etc/prometheus/prometheus.yml'\n",
    "      - '--storage.tsdb.path=/prometheus'\n",
    "      - '--web.console.libraries=/etc/prometheus/console_libraries'\n",
    "      - '--web.console.templates=/etc/prometheus/consoles'\n",
    "      - '--storage.tsdb.retention.time=${PROMETHEUS_RETENTION}'\n",
    "      - '--web.enable-lifecycle'\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "  grafana:\n",
    "    image: grafana/grafana:latest\n",
    "    ports:\n",
    "      - \"3200:3000\"\n",
    "    environment:\n",
    "      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}\n",
    "      - GF_USERS_ALLOW_SIGN_UP=false\n",
    "    volumes:\n",
    "      - grafana_data:/var/lib/grafana\n",
    "      - ./config/grafana/provisioning:/etc/grafana/provisioning:ro\n",
    "    depends_on:\n",
    "      - prometheus\n",
    "    networks:\n",
    "      - mycology-network\n",
    "    restart: unless-stopped\n",
    "\n",
    "# Persistent Data Volumes\n",
    "volumes:\n",
    "  postgres_data:\n",
    "    driver: local\n",
    "  redis_data:\n",
    "    driver: local\n",
    "  cv_models:\n",
    "    driver: local\n",
    "  analysis_data:\n",
    "    driver: local\n",
    "  bioactivity_models:\n",
    "    driver: local\n",
    "  bioactivity_data:\n",
    "    driver: local\n",
    "  export_files:\n",
    "    driver: local\n",
    "  report_templates:\n",
    "    driver: local\n",
    "  prometheus_data:\n",
    "    driver: local\n",
    "  grafana_data:\n",
    "    driver: local\n",
    "\n",
    "# Network Configuration\n",
    "networks:\n",
    "  mycology-network:\n",
    "    driver: bridge\n",
    "    ipam:\n",
    "      config:\n",
    "        - subnet: 172.20.0.0/16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533ea2c",
   "metadata": {},
   "source": [
    "## 3. Service Container Definitions\n",
    "\n",
    "### üê≥ Individual Service Dockerfiles\n",
    "\n",
    "Each microservice needs its own Dockerfile optimized for its technology stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc505fe",
   "metadata": {
    "vscode": {
     "languageId": "dockerfile"
    }
   },
   "outputs": [],
   "source": [
    "# Python Services Dockerfile Template\n",
    "# Use for: computer-vision-service, bioactivity-service, literature-service, etc.\n",
    "\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    gcc \\\n",
    "    g++ \\\n",
    "    libgl1-mesa-glx \\\n",
    "    libglib2.0-0 \\\n",
    "    libsm6 \\\n",
    "    libxext6 \\\n",
    "    libxrender-dev \\\n",
    "    libgomp1 \\\n",
    "    curl \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Create non-root user for security\n",
    "RUN groupadd -r appuser && useradd -r -g appuser appuser\n",
    "\n",
    "# Copy requirements first for better Docker layer caching\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Install Python dependencies\n",
    "RUN pip install --no-cache-dir --upgrade pip && \\\n",
    "    pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy application code\n",
    "COPY . .\n",
    "\n",
    "# Create necessary directories\n",
    "RUN mkdir -p /app/models /app/data /app/logs && \\\n",
    "    chown -R appuser:appuser /app\n",
    "\n",
    "# Switch to non-root user\n",
    "USER appuser\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \\\n",
    "    CMD curl -f http://localhost:${PORT:-5000}/health || exit 1\n",
    "\n",
    "# Expose port (will be overridden by specific services)\n",
    "EXPOSE 5000\n",
    "\n",
    "# Default command (will be overridden by specific services)\n",
    "CMD [\"python\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf055bd",
   "metadata": {
    "vscode": {
     "languageId": "dockerfile"
    }
   },
   "outputs": [],
   "source": [
    "# Node.js Services Dockerfile Template\n",
    "# Use for: chat-ai-service, health-monitoring, notification-service, batch-tracking-service\n",
    "\n",
    "FROM node:18-alpine\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system dependencies for Alpine\n",
    "RUN apk add --no-cache \\\n",
    "    curl \\\n",
    "    dumb-init\n",
    "\n",
    "# Create non-root user\n",
    "RUN addgroup -g 1001 -S nodejs && \\\n",
    "    adduser -S nextjs -u 1001\n",
    "\n",
    "# Copy package files\n",
    "COPY package*.json ./\n",
    "COPY tsconfig.json ./\n",
    "\n",
    "# Install dependencies\n",
    "RUN npm ci --only=production && npm cache clean --force\n",
    "\n",
    "# Copy source code\n",
    "COPY . .\n",
    "\n",
    "# Build TypeScript (if applicable)\n",
    "RUN npm run build 2>/dev/null || echo \"No build script found\"\n",
    "\n",
    "# Create necessary directories\n",
    "RUN mkdir -p /app/logs /app/uploads && \\\n",
    "    chown -R nextjs:nodejs /app\n",
    "\n",
    "# Switch to non-root user\n",
    "USER nextjs\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \\\n",
    "    CMD curl -f http://localhost:${PORT:-3000}/health || exit 1\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 3000\n",
    "\n",
    "# Use dumb-init to handle signals properly\n",
    "ENTRYPOINT [\"dumb-init\", \"--\"]\n",
    "\n",
    "# Start the application\n",
    "CMD [\"npm\", \"start\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44283414",
   "metadata": {},
   "source": [
    "## 4. Database and Redis Configuration\n",
    "\n",
    "### üóÑÔ∏è PostgreSQL Multi-Database Setup\n",
    "\n",
    "Initialize multiple databases for service isolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85c0e9",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# init-databases.sh - Initialize multiple PostgreSQL databases\n",
    "set -e\n",
    "\n",
    "echo \"üóÑÔ∏è Initializing PostgreSQL databases for Unified Mycology Platform...\"\n",
    "\n",
    "# Create databases for each service\n",
    "psql -v ON_ERROR_STOP=1 --username \"$POSTGRES_USER\" --dbname \"$POSTGRES_DB\" <<-EOSQL\n",
    "    -- Computer Vision Service Database\n",
    "    CREATE DATABASE computer_vision;\n",
    "    GRANT ALL PRIVILEGES ON DATABASE computer_vision TO $POSTGRES_USER;\n",
    "    \n",
    "    -- Bioactivity ML Service Database\n",
    "    CREATE DATABASE bioactivity;\n",
    "    GRANT ALL PRIVILEGES ON DATABASE bioactivity TO $POSTGRES_USER;\n",
    "    \n",
    "    -- Literature Search Service Database\n",
    "    CREATE DATABASE literature;\n",
    "    GRANT ALL PRIVILEGES ON DATABASE literature TO $POSTGRES_USER;\n",
    "    \n",
    "    -- Batch Processing Service Database\n",
    "    CREATE DATABASE batch_processing;\n",
    "    GRANT ALL PRIVILEGES ON DATABASE batch_processing TO $POSTGRES_USER;\n",
    "    \n",
    "    -- Notification Service Database\n",
    "    CREATE DATABASE notifications;\n",
    "    GRANT ALL PRIVILEGES ON DATABASE notifications TO $POSTGRES_USER;\n",
    "    \n",
    "    -- Batch Tracking Service Database\n",
    "    CREATE DATABASE batch_tracking;\n",
    "    GRANT ALL PRIVILEGES ON DATABASE batch_tracking TO $POSTGRES_USER;\n",
    "    \n",
    "    -- Authentication Service Database\n",
    "    CREATE DATABASE auth;\n",
    "    GRANT ALL PRIVILEGES ON DATABASE auth TO $POSTGRES_USER;\n",
    "    \n",
    "    -- Payment Service Database\n",
    "    CREATE DATABASE payments;\n",
    "    GRANT ALL PRIVILEGES ON DATABASE payments TO $POSTGRES_USER;\n",
    "    \n",
    "    -- Export & Reporting Service Database\n",
    "    CREATE DATABASE exports;\n",
    "    GRANT ALL PRIVILEGES ON DATABASE exports TO $POSTGRES_USER;\n",
    "    \n",
    "    -- Chat AI Service Database\n",
    "    CREATE DATABASE chat_ai;\n",
    "    GRANT ALL PRIVILEGES ON DATABASE chat_ai TO $POSTGRES_USER;\n",
    "EOSQL\n",
    "\n",
    "echo \"‚úÖ All databases created successfully!\"\n",
    "\n",
    "# Create extensions for specific databases if needed\n",
    "echo \"üîß Installing PostgreSQL extensions...\"\n",
    "\n",
    "psql -v ON_ERROR_STOP=1 --username \"$POSTGRES_USER\" --dbname \"computer_vision\" <<-EOSQL\n",
    "    CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n",
    "    CREATE EXTENSION IF NOT EXISTS \"pg_trgm\";\n",
    "EOSQL\n",
    "\n",
    "psql -v ON_ERROR_STOP=1 --username \"$POSTGRES_USER\" --dbname \"bioactivity\" <<-EOSQL\n",
    "    CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n",
    "EOSQL\n",
    "\n",
    "psql -v ON_ERROR_STOP=1 --username \"$POSTGRES_USER\" --dbname \"literature\" <<-EOSQL\n",
    "    CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n",
    "    CREATE EXTENSION IF NOT EXISTS \"pg_trgm\";\n",
    "EOSQL\n",
    "\n",
    "echo \"‚úÖ PostgreSQL extensions installed successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9e5cc",
   "metadata": {},
   "source": [
    "## 5. API Gateway with Nginx\n",
    "\n",
    "### üåê Nginx Configuration for Unified Platform Routing\n",
    "\n",
    "Nginx serves as the single entry point, routing requests to appropriate microservices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e73c5",
   "metadata": {
    "vscode": {
     "languageId": "nginx"
    }
   },
   "outputs": [],
   "source": [
    "# nginx.conf - API Gateway Configuration for Unified Mycology Platform\n",
    "events {\n",
    "    worker_connections 1024;\n",
    "    use epoll;\n",
    "    multi_accept on;\n",
    "}\n",
    "\n",
    "http {\n",
    "    # Basic Settings\n",
    "    include /etc/nginx/mime.types;\n",
    "    default_type application/octet-stream;\n",
    "    \n",
    "    # Performance Optimizations\n",
    "    sendfile on;\n",
    "    tcp_nopush on;\n",
    "    tcp_nodelay on;\n",
    "    keepalive_timeout 65;\n",
    "    types_hash_max_size 2048;\n",
    "    \n",
    "    # Gzip Compression\n",
    "    gzip on;\n",
    "    gzip_vary on;\n",
    "    gzip_min_length 1024;\n",
    "    gzip_comp_level 6;\n",
    "    gzip_types\n",
    "        text/plain\n",
    "        text/css\n",
    "        text/xml\n",
    "        text/javascript\n",
    "        application/json\n",
    "        application/javascript\n",
    "        application/xml+rss\n",
    "        application/atom+xml\n",
    "        image/svg+xml;\n",
    "\n",
    "    # Rate Limiting\n",
    "    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;\n",
    "    limit_req_zone $binary_remote_addr zone=upload:10m rate=2r/s;\n",
    "\n",
    "    # Upstream Service Definitions\n",
    "    upstream chat_ai {\n",
    "        server chat-ai-service:3000 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream computer_vision {\n",
    "        server computer-vision-service:5001 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream bioactivity {\n",
    "        server bioactivity-service:5002 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream literature {\n",
    "        server literature-service:5003 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream batch_processing {\n",
    "        server batch-processing-service:5004 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream auth {\n",
    "        server auth-service:5005 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream payment {\n",
    "        server payment-service:5006 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream export {\n",
    "        server export-service:5007 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream health {\n",
    "        server health-monitoring:3001 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream notification {\n",
    "        server notification-service:3002 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream batch_tracking {\n",
    "        server batch-tracking-service:3003 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    upstream frontend {\n",
    "        server frontend:3000 max_fails=3 fail_timeout=30s;\n",
    "        keepalive 32;\n",
    "    }\n",
    "    \n",
    "    # Main Server Configuration\n",
    "    server {\n",
    "        listen 80;\n",
    "        server_name localhost;\n",
    "        \n",
    "        # Security Headers\n",
    "        add_header X-Frame-Options \"SAMEORIGIN\" always;\n",
    "        add_header X-Content-Type-Options \"nosniff\" always;\n",
    "        add_header X-XSS-Protection \"1; mode=block\" always;\n",
    "        add_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n",
    "        \n",
    "        # Logging\n",
    "        access_log /var/log/nginx/access.log;\n",
    "        error_log /var/log/nginx/error.log;\n",
    "        \n",
    "        # Frontend Application\n",
    "        location / {\n",
    "            proxy_pass http://frontend;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "            \n",
    "            # WebSocket support for Next.js hot reload\n",
    "            proxy_http_version 1.1;\n",
    "            proxy_set_header Upgrade $http_upgrade;\n",
    "            proxy_set_header Connection \"upgrade\";\n",
    "        }\n",
    "        \n",
    "        # Chat AI Service Routes\n",
    "        location /api/chat/ {\n",
    "            limit_req zone=api burst=20 nodelay;\n",
    "            \n",
    "            proxy_pass http://chat_ai/api/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "            \n",
    "            # Timeout settings for AI responses\n",
    "            proxy_connect_timeout 60s;\n",
    "            proxy_send_timeout 60s;\n",
    "            proxy_read_timeout 120s;\n",
    "        }\n",
    "        \n",
    "        # Computer Vision Service Routes (with special upload handling)\n",
    "        location /api/vision/ {\n",
    "            limit_req zone=upload burst=5 nodelay;\n",
    "            \n",
    "            proxy_pass http://computer_vision/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "            \n",
    "            # Large file upload support for images\n",
    "            client_max_body_size 50M;\n",
    "            client_body_timeout 60s;\n",
    "            \n",
    "            # Extended timeouts for ML processing\n",
    "            proxy_connect_timeout 60s;\n",
    "            proxy_send_timeout 180s;\n",
    "            proxy_read_timeout 300s;\n",
    "        }\n",
    "        \n",
    "        # Bioactivity ML Service Routes\n",
    "        location /api/bioactivity/ {\n",
    "            limit_req zone=api burst=10 nodelay;\n",
    "            \n",
    "            proxy_pass http://bioactivity/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "            \n",
    "            # Extended timeouts for ML predictions\n",
    "            proxy_connect_timeout 30s;\n",
    "            proxy_send_timeout 60s;\n",
    "            proxy_read_timeout 120s;\n",
    "        }\n",
    "        \n",
    "        # Literature Search Service Routes\n",
    "        location /api/literature/ {\n",
    "            limit_req zone=api burst=15 nodelay;\n",
    "            \n",
    "            proxy_pass http://literature/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "        }\n",
    "        \n",
    "        # Batch Processing Service Routes\n",
    "        location /api/batch/ {\n",
    "            limit_req zone=api burst=10 nodelay;\n",
    "            \n",
    "            proxy_pass http://batch_processing/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "        }\n",
    "        \n",
    "        # Authentication Service Routes\n",
    "        location /api/auth/ {\n",
    "            limit_req zone=api burst=10 nodelay;\n",
    "            \n",
    "            proxy_pass http://auth/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "        }\n",
    "        \n",
    "        # Payment Service Routes\n",
    "        location /api/payment/ {\n",
    "            limit_req zone=api burst=5 nodelay;\n",
    "            \n",
    "            proxy_pass http://payment/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "        }\n",
    "        \n",
    "        # Export & Reporting Service Routes\n",
    "        location /api/export/ {\n",
    "            limit_req zone=api burst=5 nodelay;\n",
    "            \n",
    "            proxy_pass http://export/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "            \n",
    "            # Large timeouts for report generation\n",
    "            proxy_connect_timeout 30s;\n",
    "            proxy_send_timeout 120s;\n",
    "            proxy_read_timeout 300s;\n",
    "        }\n",
    "        \n",
    "        # Health Monitoring Service Routes\n",
    "        location /api/health {\n",
    "            proxy_pass http://health/health;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "        }\n",
    "        \n",
    "        # Notification Service Routes\n",
    "        location /api/notifications/ {\n",
    "            limit_req zone=api burst=20 nodelay;\n",
    "            \n",
    "            proxy_pass http://notification/api/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "            \n",
    "            # WebSocket support for real-time notifications\n",
    "            proxy_http_version 1.1;\n",
    "            proxy_set_header Upgrade $http_upgrade;\n",
    "            proxy_set_header Connection \"upgrade\";\n",
    "        }\n",
    "        \n",
    "        # Batch Tracking Service Routes\n",
    "        location /api/batches/ {\n",
    "            limit_req zone=api burst=15 nodelay;\n",
    "            \n",
    "            proxy_pass http://batch_tracking/api/;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "        }\n",
    "        \n",
    "        # Static file serving with caching\n",
    "        location ~* \\.(js|css|png|jpg|jpeg|gif|ico|svg)$ {\n",
    "            expires 1y;\n",
    "            add_header Cache-Control \"public, immutable\";\n",
    "            access_log off;\n",
    "        }\n",
    "        \n",
    "        # Health check endpoint\n",
    "        location /nginx-health {\n",
    "            access_log off;\n",
    "            return 200 \"healthy\\n\";\n",
    "            add_header Content-Type text/plain;\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10227b",
   "metadata": {},
   "source": [
    "## 6. Health Monitoring and Observability\n",
    "\n",
    "### üìä Prometheus + Grafana Monitoring Stack\n",
    "\n",
    "Complete monitoring solution for the unified platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e30017",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "# config/prometheus/prometheus.yml - Monitoring Configuration\n",
    "global:\n",
    "  scrape_interval: 15s\n",
    "  evaluation_interval: 15s\n",
    "\n",
    "rule_files:\n",
    "  - \"alert_rules.yml\"\n",
    "\n",
    "alerting:\n",
    "  alertmanagers:\n",
    "    - static_configs:\n",
    "        - targets: []\n",
    "\n",
    "scrape_configs:\n",
    "  # Prometheus itself\n",
    "  - job_name: 'prometheus'\n",
    "    static_configs:\n",
    "      - targets: ['localhost:9090']\n",
    "\n",
    "  # Node.js Services\n",
    "  - job_name: 'chat-ai-service'\n",
    "    static_configs:\n",
    "      - targets: ['chat-ai-service:3000']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "    \n",
    "  - job_name: 'health-monitoring'\n",
    "    static_configs:\n",
    "      - targets: ['health-monitoring:3001']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  - job_name: 'notification-service'\n",
    "    static_configs:\n",
    "      - targets: ['notification-service:3002']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  - job_name: 'batch-tracking-service'\n",
    "    static_configs:\n",
    "      - targets: ['batch-tracking-service:3003']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  # Python Services\n",
    "  - job_name: 'computer-vision-service'\n",
    "    static_configs:\n",
    "      - targets: ['computer-vision-service:5001']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  - job_name: 'bioactivity-service'\n",
    "    static_configs:\n",
    "      - targets: ['bioactivity-service:5002']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  - job_name: 'literature-service'\n",
    "    static_configs:\n",
    "      - targets: ['literature-service:5003']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  - job_name: 'batch-processing-service'\n",
    "    static_configs:\n",
    "      - targets: ['batch-processing-service:5004']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  - job_name: 'auth-service'\n",
    "    static_configs:\n",
    "      - targets: ['auth-service:5005']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  - job_name: 'payment-service'\n",
    "    static_configs:\n",
    "      - targets: ['payment-service:5006']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  - job_name: 'export-service'\n",
    "    static_configs:\n",
    "      - targets: ['export-service:5007']\n",
    "    metrics_path: '/metrics'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  # Infrastructure Services\n",
    "  - job_name: 'nginx'\n",
    "    static_configs:\n",
    "      - targets: ['api-gateway:80']\n",
    "    metrics_path: '/nginx-status'\n",
    "    scrape_interval: 30s\n",
    "\n",
    "  - job_name: 'postgres'\n",
    "    static_configs:\n",
    "      - targets: ['postgres:5432']\n",
    "    scrape_interval: 60s\n",
    "\n",
    "  - job_name: 'redis'\n",
    "    static_configs:\n",
    "      - targets: ['redis:6379']\n",
    "    scrape_interval: 60s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e5d0fc",
   "metadata": {},
   "source": [
    "## 7. Testing Service Connectivity\n",
    "\n",
    "### üß™ Comprehensive Testing Suite\n",
    "\n",
    "Verify all services are running and communicating properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f33b9b",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# test-platform.sh - Comprehensive Platform Testing Suite\n",
    "\n",
    "echo \"üß™ Testing Unified Mycology Platform...\"\n",
    "echo \"========================================\"\n",
    "\n",
    "# Colors for output\n",
    "RED='\\033[0;31m'\n",
    "GREEN='\\033[0;32m'\n",
    "YELLOW='\\033[1;33m'\n",
    "BLUE='\\033[0;34m'\n",
    "NC='\\033[0m' # No Color\n",
    "\n",
    "# Test function\n",
    "test_endpoint() {\n",
    "    local url=$1\n",
    "    local name=$2\n",
    "    local expected_code=${3:-200}\n",
    "    \n",
    "    echo -n \"Testing $name... \"\n",
    "    \n",
    "    response=$(curl -s -o /dev/null -w \"%{http_code}\" \"$url\" --max-time 10)\n",
    "    \n",
    "    if [ \"$response\" = \"$expected_code\" ]; then\n",
    "        echo -e \"${GREEN}‚úÖ PASS${NC} ($response)\"\n",
    "        return 0\n",
    "    else\n",
    "        echo -e \"${RED}‚ùå FAIL${NC} ($response)\"\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Test function with JSON response\n",
    "test_json_endpoint() {\n",
    "    local url=$1\n",
    "    local name=$2\n",
    "    \n",
    "    echo -n \"Testing $name... \"\n",
    "    \n",
    "    response=$(curl -s \"$url\" --max-time 10)\n",
    "    \n",
    "    if echo \"$response\" | jq . >/dev/null 2>&1; then\n",
    "        echo -e \"${GREEN}‚úÖ PASS${NC} (Valid JSON)\"\n",
    "        return 0\n",
    "    else\n",
    "        echo -e \"${RED}‚ùå FAIL${NC} (Invalid JSON or timeout)\"\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Wait for services to be ready\n",
    "echo -e \"${BLUE}üîÑ Waiting for services to be ready...${NC}\"\n",
    "sleep 30\n",
    "\n",
    "failed_tests=0\n",
    "\n",
    "echo -e \"\\n${BLUE}üèóÔ∏è Testing Infrastructure Services${NC}\"\n",
    "echo \"----------------------------------------\"\n",
    "\n",
    "# Test API Gateway\n",
    "test_endpoint \"http://localhost/nginx-health\" \"API Gateway Health\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "# Test Database\n",
    "test_endpoint \"http://localhost:5432\" \"PostgreSQL Connection\" \"000\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "# Test Redis\n",
    "echo -n \"Testing Redis Connection... \"\n",
    "if docker-compose exec -T redis redis-cli ping >/dev/null 2>&1; then\n",
    "    echo -e \"${GREEN}‚úÖ PASS${NC}\"\n",
    "else\n",
    "    echo -e \"${RED}‚ùå FAIL${NC}\"\n",
    "    ((failed_tests++))\n",
    "fi\n",
    "\n",
    "echo -e \"\\n${BLUE}üîç Testing Individual Service Health Endpoints${NC}\"\n",
    "echo \"----------------------------------------------\"\n",
    "\n",
    "# Test all service health endpoints\n",
    "test_json_endpoint \"http://localhost:3001/health\" \"Health Monitoring Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_json_endpoint \"http://localhost:3000/health\" \"Chat AI Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_json_endpoint \"http://localhost:5001/health\" \"Computer Vision Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_json_endpoint \"http://localhost:5002/health\" \"Bioactivity Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_json_endpoint \"http://localhost:5003/health\" \"Literature Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_json_endpoint \"http://localhost:5004/health\" \"Batch Processing Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_json_endpoint \"http://localhost:5005/health\" \"Auth Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_json_endpoint \"http://localhost:5006/health\" \"Payment Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_json_endpoint \"http://localhost:5007/health\" \"Export Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_json_endpoint \"http://localhost:3002/health\" \"Notification Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_json_endpoint \"http://localhost:3003/health\" \"Batch Tracking Service\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "echo -e \"\\n${BLUE}üåê Testing API Gateway Routing${NC}\"\n",
    "echo \"--------------------------------\"\n",
    "\n",
    "# Test API routing through gateway\n",
    "test_json_endpoint \"http://localhost/api/health\" \"Gateway -> Health Monitoring\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_endpoint \"http://localhost/api/chat/health\" \"Gateway -> Chat AI\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_endpoint \"http://localhost/api/vision/health\" \"Gateway -> Computer Vision\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_endpoint \"http://localhost/api/bioactivity/health\" \"Gateway -> Bioactivity\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_endpoint \"http://localhost/api/literature/health\" \"Gateway -> Literature\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "echo -e \"\\n${BLUE}üîÑ Testing Inter-Service Communication${NC}\"\n",
    "echo \"--------------------------------------\"\n",
    "\n",
    "# Test service-to-service communication\n",
    "echo -n \"Testing Chat AI -> Computer Vision integration... \"\n",
    "response=$(curl -s -X POST \"http://localhost/api/chat/test-integration\" \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d '{\"service\": \"computer-vision\", \"test\": true}' --max-time 15)\n",
    "\n",
    "if echo \"$response\" | grep -q \"integration_successful\"; then\n",
    "    echo -e \"${GREEN}‚úÖ PASS${NC}\"\n",
    "else\n",
    "    echo -e \"${RED}‚ùå FAIL${NC}\"\n",
    "    ((failed_tests++))\n",
    "fi\n",
    "\n",
    "echo -e \"\\n${BLUE}üìä Testing Monitoring Stack${NC}\"\n",
    "echo \"----------------------------\"\n",
    "\n",
    "test_endpoint \"http://localhost:9090/-/healthy\" \"Prometheus Health\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_endpoint \"http://localhost:3200/api/health\" \"Grafana Health\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "echo -e \"\\n${BLUE}üéØ Testing Complete Analysis Workflow${NC}\"\n",
    "echo \"------------------------------------\"\n",
    "\n",
    "# Test complete workflow with mock data\n",
    "echo -n \"Testing complete analysis workflow... \"\n",
    "response=$(curl -s -X POST \"http://localhost/api/chat/analyze-and-chat\" \\\n",
    "    -F \"image=@test-mushroom.jpg\" \\\n",
    "    -F \"userId=test-user\" \\\n",
    "    -F \"analysisType=identify\" \\\n",
    "    -F \"message=What species is this?\" --max-time 60 2>/dev/null)\n",
    "\n",
    "if [ $? -eq 0 ] && echo \"$response\" | grep -q \"analysis\"; then\n",
    "    echo -e \"${GREEN}‚úÖ PASS${NC}\"\n",
    "else\n",
    "    echo -e \"${YELLOW}‚ö†Ô∏è  SKIP${NC} (No test image or service not ready)\"\n",
    "fi\n",
    "\n",
    "echo -e \"\\n${BLUE}üì± Testing Frontend Application${NC}\"\n",
    "echo \"-------------------------------\"\n",
    "\n",
    "test_endpoint \"http://localhost:3100\" \"Frontend Application\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "test_endpoint \"http://localhost\" \"Frontend via Gateway\"\n",
    "[ $? -ne 0 ] && ((failed_tests++))\n",
    "\n",
    "echo -e \"\\n========================================\"\n",
    "echo -e \"${BLUE}üéØ Test Results Summary${NC}\"\n",
    "echo \"========================================\"\n",
    "\n",
    "if [ $failed_tests -eq 0 ]; then\n",
    "    echo -e \"${GREEN}‚úÖ ALL TESTS PASSED!${NC}\"\n",
    "    echo -e \"${GREEN}üöÄ Unified Mycology Platform is ready for use!${NC}\"\n",
    "    echo \"\"\n",
    "    echo -e \"${BLUE}Access Points:${NC}\"\n",
    "    echo \"‚Ä¢ Frontend: http://localhost:3100\"\n",
    "    echo \"‚Ä¢ API Gateway: http://localhost\"\n",
    "    echo \"‚Ä¢ Health Dashboard: http://localhost:3001\"\n",
    "    echo \"‚Ä¢ Grafana: http://localhost:3200 (admin/admin)\"\n",
    "    echo \"‚Ä¢ Prometheus: http://localhost:9090\"\n",
    "    exit 0\n",
    "else\n",
    "    echo -e \"${RED}‚ùå $failed_tests tests failed${NC}\"\n",
    "    echo -e \"${YELLOW}üîß Check service logs: docker-compose logs [service-name]${NC}\"\n",
    "    echo -e \"${YELLOW}üí° Run: docker-compose ps to check service status${NC}\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22409393",
   "metadata": {},
   "source": [
    "## 8. Scaling and Load Balancing\n",
    "\n",
    "### üìà Production Scaling Configuration\n",
    "\n",
    "Configure horizontal scaling and load balancing for high-availability deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287a8947",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "# docker-compose.override.yml - Production Scaling Configuration\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  # Scale compute-intensive services\n",
    "  computer-vision-service:\n",
    "    deploy:\n",
    "      replicas: 3\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 4G\n",
    "          cpus: '2'\n",
    "        reservations:\n",
    "          memory: 2G\n",
    "          cpus: '1'\n",
    "      restart_policy:\n",
    "        condition: on-failure\n",
    "        delay: 10s\n",
    "        max_attempts: 3\n",
    "        window: 120s\n",
    "      update_config:\n",
    "        parallelism: 1\n",
    "        delay: 30s\n",
    "        order: start-first\n",
    "        failure_action: rollback\n",
    "\n",
    "  bioactivity-service:\n",
    "    deploy:\n",
    "      replicas: 2\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 8G\n",
    "          cpus: '4'\n",
    "        reservations:\n",
    "          memory: 4G\n",
    "          cpus: '2'\n",
    "      restart_policy:\n",
    "        condition: on-failure\n",
    "        delay: 10s\n",
    "        max_attempts: 3\n",
    "\n",
    "  chat-ai-service:\n",
    "    deploy:\n",
    "      replicas: 3\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 2G\n",
    "          cpus: '1'\n",
    "        reservations:\n",
    "          memory: 1G\n",
    "          cpus: '0.5'\n",
    "      restart_policy:\n",
    "        condition: on-failure\n",
    "        delay: 5s\n",
    "        max_attempts: 3\n",
    "\n",
    "  literature-service:\n",
    "    deploy:\n",
    "      replicas: 2\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 1G\n",
    "          cpus: '1'\n",
    "        reservations:\n",
    "          memory: 512M\n",
    "          cpus: '0.5'\n",
    "\n",
    "  # Scale API Gateway for high throughput\n",
    "  api-gateway:\n",
    "    deploy:\n",
    "      replicas: 2\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 512M\n",
    "          cpus: '1'\n",
    "        reservations:\n",
    "          memory: 256M\n",
    "          cpus: '0.5'\n",
    "\n",
    "  # Scale Celery workers for batch processing\n",
    "  celery-worker:\n",
    "    deploy:\n",
    "      replicas: 4\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 2G\n",
    "          cpus: '2'\n",
    "        reservations:\n",
    "          memory: 1G\n",
    "          cpus: '1'\n",
    "\n",
    "  # Database with performance tuning\n",
    "  postgres:\n",
    "    command: >\n",
    "      postgres \n",
    "      -c max_connections=200\n",
    "      -c shared_buffers=256MB\n",
    "      -c effective_cache_size=1GB\n",
    "      -c maintenance_work_mem=64MB\n",
    "      -c checkpoint_completion_target=0.7\n",
    "      -c wal_buffers=16MB\n",
    "      -c default_statistics_target=100\n",
    "      -c random_page_cost=1.1\n",
    "      -c effective_io_concurrency=200\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 2G\n",
    "          cpus: '2'\n",
    "        reservations:\n",
    "          memory: 1G\n",
    "          cpus: '1'\n",
    "\n",
    "  # Redis with performance tuning\n",
    "  redis:\n",
    "    command: >\n",
    "      redis-server \n",
    "      --appendonly yes \n",
    "      --requirepass ${REDIS_PASSWORD}\n",
    "      --maxmemory 1gb\n",
    "      --maxmemory-policy allkeys-lru\n",
    "      --save 900 1\n",
    "      --save 300 10\n",
    "      --save 60 10000\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          memory: 1G\n",
    "          cpus: '1'\n",
    "        reservations:\n",
    "          memory: 512M\n",
    "          cpus: '0.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c6088",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# deploy-platform.sh - Complete Deployment Script\n",
    "\n",
    "echo \"üöÄ Deploying Unified Mycology Platform...\"\n",
    "echo \"========================================\"\n",
    "\n",
    "# Validate environment\n",
    "echo \"üîç Validating environment...\"\n",
    "\n",
    "# Check if Docker is running\n",
    "if ! docker info >/dev/null 2>&1; then\n",
    "    echo \"‚ùå Docker is not running. Please start Docker first.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Check if .env file exists\n",
    "if [ ! -f \".env\" ]; then\n",
    "    echo \"‚ùå .env file not found. Please copy .env.example to .env and configure it.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Check required environment variables\n",
    "source .env\n",
    "required_vars=(\n",
    "    \"OPENAI_API_KEY\"\n",
    "    \"POSTGRES_PASSWORD\"\n",
    "    \"REDIS_PASSWORD\"\n",
    "    \"JWT_SECRET_KEY\"\n",
    ")\n",
    "\n",
    "for var in \"${required_vars[@]}\"; do\n",
    "    if [ -z \"${!var}\" ]; then\n",
    "        echo \"‚ùå Required environment variable $var is not set in .env\"\n",
    "        exit 1\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"‚úÖ Environment validation passed\"\n",
    "\n",
    "# Create necessary directories\n",
    "echo \"üìÅ Creating directories...\"\n",
    "mkdir -p data/{postgres,redis,logs}\n",
    "mkdir -p config/{nginx,prometheus,grafana,ssl}\n",
    "mkdir -p scripts/{deployment,monitoring,backup}\n",
    "\n",
    "# Set appropriate permissions\n",
    "chmod +x init-databases.sh\n",
    "chmod +x test-platform.sh\n",
    "\n",
    "echo \"‚úÖ Directories created\"\n",
    "\n",
    "# Pull latest images\n",
    "echo \"üì• Pulling latest Docker images...\"\n",
    "docker-compose pull\n",
    "\n",
    "# Build services\n",
    "echo \"üèóÔ∏è Building services...\"\n",
    "docker-compose build --parallel\n",
    "\n",
    "# Start infrastructure services first\n",
    "echo \"üõ†Ô∏è Starting infrastructure services...\"\n",
    "docker-compose up -d postgres redis\n",
    "\n",
    "# Wait for databases to be ready\n",
    "echo \"‚è≥ Waiting for databases to initialize...\"\n",
    "sleep 30\n",
    "\n",
    "# Health check for PostgreSQL\n",
    "echo \"üîç Checking PostgreSQL connection...\"\n",
    "until docker-compose exec -T postgres pg_isready -U postgres >/dev/null 2>&1; do\n",
    "    echo \"Waiting for PostgreSQL...\"\n",
    "    sleep 5\n",
    "done\n",
    "echo \"‚úÖ PostgreSQL is ready\"\n",
    "\n",
    "# Health check for Redis\n",
    "echo \"üîç Checking Redis connection...\"\n",
    "until docker-compose exec -T redis redis-cli ping >/dev/null 2>&1; do\n",
    "    echo \"Waiting for Redis...\"\n",
    "    sleep 5\n",
    "done\n",
    "echo \"‚úÖ Redis is ready\"\n",
    "\n",
    "# Start all services\n",
    "echo \"üöÄ Starting all services...\"\n",
    "docker-compose up -d\n",
    "\n",
    "# Wait for services to be ready\n",
    "echo \"‚è≥ Waiting for services to start...\"\n",
    "sleep 60\n",
    "\n",
    "# Run health checks\n",
    "echo \"üß™ Running health checks...\"\n",
    "./test-platform.sh\n",
    "\n",
    "if [ $? -eq 0 ]; then\n",
    "    echo \"\"\n",
    "    echo \"üéâ Deployment successful!\"\n",
    "    echo \"==========================\"\n",
    "    echo \"\"\n",
    "    echo \"üåê Access Points:\"\n",
    "    echo \"‚Ä¢ Frontend Application: http://localhost:3100\"\n",
    "    echo \"‚Ä¢ API Gateway: http://localhost\"\n",
    "    echo \"‚Ä¢ Health Dashboard: http://localhost:3001\"\n",
    "    echo \"‚Ä¢ Grafana Monitoring: http://localhost:3200 (admin/admin)\"\n",
    "    echo \"‚Ä¢ Prometheus Metrics: http://localhost:9090\"\n",
    "    echo \"\"\n",
    "    echo \"üìä Service Status:\"\n",
    "    docker-compose ps\n",
    "    echo \"\"\n",
    "    echo \"üìù Useful Commands:\"\n",
    "    echo \"‚Ä¢ View logs: docker-compose logs -f [service-name]\"\n",
    "    echo \"‚Ä¢ Scale service: docker-compose up -d --scale computer-vision-service=3\"\n",
    "    echo \"‚Ä¢ Stop platform: docker-compose down\"\n",
    "    echo \"‚Ä¢ Update service: docker-compose build [service-name] && docker-compose up -d [service-name]\"\n",
    "    echo \"\"\n",
    "    echo \"üéØ Next Steps:\"\n",
    "    echo \"1. Upload test images to verify computer vision analysis\"\n",
    "    echo \"2. Test AI chat with mycology questions\"\n",
    "    echo \"3. Create batch tracking entries\"\n",
    "    echo \"4. Monitor service health in Grafana\"\n",
    "    echo \"5. Set up SSL certificates for production\"\n",
    "else\n",
    "    echo \"\"\n",
    "    echo \"‚ùå Deployment completed with errors\"\n",
    "    echo \"Please check service logs: docker-compose logs\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea18692",
   "metadata": {},
   "source": [
    "## üéØ Quick Start Guide Summary\n",
    "\n",
    "### üöÄ Deploy in 5 Minutes\n",
    "\n",
    "**1. Clone and Setup:**\n",
    "```bash\n",
    "git clone your-repo\n",
    "cd unified-mycology-platform\n",
    "cp .env.example .env\n",
    "# Edit .env with your API keys\n",
    "```\n",
    "\n",
    "**2. Deploy Platform:**\n",
    "```bash\n",
    "chmod +x deploy-platform.sh\n",
    "./deploy-platform.sh\n",
    "```\n",
    "\n",
    "**3. Access Your Platform:**\n",
    "- **Frontend:** http://localhost:3100\n",
    "- **API Gateway:** http://localhost\n",
    "- **Health Dashboard:** http://localhost:3001\n",
    "- **Grafana:** http://localhost:3200 (admin/admin)\n",
    "\n",
    "### ‚úÖ Success Indicators\n",
    "\n",
    "- ‚úÖ All services show \"healthy\" status\n",
    "- ‚úÖ Image upload and analysis works\n",
    "- ‚úÖ AI chat responses include analysis context\n",
    "- ‚úÖ Notifications are sent\n",
    "- ‚úÖ Frontend loads and displays data\n",
    "- ‚úÖ Grafana shows service metrics\n",
    "\n",
    "### üîß Common Commands\n",
    "\n",
    "```bash\n",
    "# View service status\n",
    "docker-compose ps\n",
    "\n",
    "# View service logs\n",
    "docker-compose logs -f computer-vision-service\n",
    "\n",
    "# Scale a service\n",
    "docker-compose up -d --scale chat-ai-service=3\n",
    "\n",
    "# Restart a service\n",
    "docker-compose restart chat-ai-service\n",
    "\n",
    "# Stop the platform\n",
    "docker-compose down\n",
    "\n",
    "# Full cleanup (removes volumes)\n",
    "docker-compose down -v\n",
    "```\n",
    "\n",
    "### üéâ What You've Built\n",
    "\n",
    "A complete **Unified Mycology Platform** that:\n",
    "\n",
    "- üîµ **Integrates Crowe Logic AI** (Node.js) with **Crowe Vision Research Pipeline** (Python)\n",
    "- üåê **Single API Gateway** routing to 11 microservices\n",
    "- üìä **Complete monitoring stack** with Prometheus + Grafana\n",
    "- üê≥ **Production-ready Docker deployment** with health checks\n",
    "- üìà **Horizontal scaling** support for high availability\n",
    "- üîÑ **Seamless workflow** from image analysis to AI insights to scientific reports\n",
    "\n",
    "### üöÄ From Monolith to Microservices\n",
    "\n",
    "You've successfully transformed CroweOS from a monolithic Next.js application into a sophisticated microservices architecture that can scale globally while maintaining all the powerful analysis capabilities of your research pipeline.\n",
    "\n",
    "**The unified platform is now ready for production deployment!** üéä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f536885",
   "metadata": {},
   "source": [
    "## üöß Implementation Roadmap - Next Steps\n",
    "\n",
    "### üìã Current Status\n",
    "‚úÖ **Architecture Design** - Complete microservices architecture documented  \n",
    "‚úÖ **Docker Compose Configuration** - Production-ready deployment setup  \n",
    "‚úÖ **API Gateway Configuration** - Nginx routing for all services  \n",
    "‚úÖ **Database Setup** - PostgreSQL + Redis with initialization scripts  \n",
    "‚úÖ **Monitoring Stack** - Prometheus + Grafana configuration  \n",
    "‚úÖ **Testing Framework** - Comprehensive testing and deployment scripts  \n",
    "\n",
    "### üéØ **Phase 1: Core Services Implementation (Week 1-2)**\n",
    "\n",
    "#### 1. **Enhanced Chat AI Service** (Priority #1)\n",
    "**Location:** `enhanced-chat-ai-service/`\n",
    "**Technology:** Node.js + TypeScript + Express\n",
    "**Key Features:**\n",
    "- Multi-provider AI routing (OpenAI + Anthropic) \n",
    "- Integration with computer vision analysis results\n",
    "- Mycology-specialized prompts and responses\n",
    "- Chat history and session management\n",
    "- Real-time streaming responses\n",
    "- Health endpoints and metrics\n",
    "\n",
    "**Implementation Steps:**\n",
    "```bash\n",
    "mkdir -p enhanced-chat-ai-service/src/{routes,services,middleware,types}\n",
    "cd enhanced-chat-ai-service\n",
    "npm init -y\n",
    "npm install express typescript @types/node openai anthropic\n",
    "```\n",
    "\n",
    "#### 2. **Computer Vision Service Extraction** (Priority #2)\n",
    "**Location:** `computer-vision-service/`\n",
    "**Technology:** Python + Flask (from existing research pipeline)\n",
    "**Key Features:**\n",
    "- Extract existing ML models and analysis logic\n",
    "- Create Flask API wrapper\n",
    "- Add health endpoints\n",
    "- Integration with Chat AI service\n",
    "- Metrics collection for monitoring\n",
    "\n",
    "**Implementation Steps:**\n",
    "```bash\n",
    "mkdir -p computer-vision-service\n",
    "# Copy existing computer vision code from research pipeline\n",
    "# Refactor into microservice architecture\n",
    "```\n",
    "\n",
    "#### 3. **Health Monitoring Service** (Priority #3)\n",
    "**Location:** `health-monitoring-service/`\n",
    "**Technology:** Node.js + TypeScript\n",
    "**Key Features:**\n",
    "- Monitor all service health endpoints\n",
    "- Aggregate health status\n",
    "- Alert system for service failures\n",
    "- Dashboard for system overview\n",
    "- Prometheus metrics integration\n",
    "\n",
    "### üéØ **Phase 2: Supporting Services (Week 2-3)**\n",
    "\n",
    "#### 4. **Notification Service**\n",
    "- Real-time notifications via WebSocket\n",
    "- Email notifications (SMTP)\n",
    "- Analysis completion alerts\n",
    "- System status notifications\n",
    "\n",
    "#### 5. **Batch Tracking Service**\n",
    "- Cultivation batch management\n",
    "- Growth stage tracking\n",
    "- Integration with computer vision for automated monitoring\n",
    "- Recipe and yield management\n",
    "\n",
    "#### 6. **Authentication Service Extraction**\n",
    "- Extract from existing research pipeline\n",
    "- JWT token management\n",
    "- User registration and login\n",
    "- Role-based permissions\n",
    "\n",
    "### üéØ **Phase 3: Integration & Polish (Week 3-4)**\n",
    "\n",
    "#### 7. **Service Integration Testing**\n",
    "- End-to-end workflow testing\n",
    "- Load testing for scaled services\n",
    "- Integration between Python and Node.js services\n",
    "- Data flow validation\n",
    "\n",
    "#### 8. **Frontend Integration**\n",
    "- Update existing frontend to consume microservices\n",
    "- Real-time features with WebSocket\n",
    "- Unified user experience\n",
    "- Error handling and loading states\n",
    "\n",
    "#### 9. **Production Optimization**\n",
    "- SSL certificate setup\n",
    "- Security hardening\n",
    "- Performance optimization\n",
    "- Backup and recovery procedures\n",
    "\n",
    "### üèÉ‚Äç‚ôÇÔ∏è **Quick Start Implementation Guide**\n",
    "\n",
    "#### **Step 1: Set Up Enhanced Chat AI Service**\n",
    "```bash\n",
    "# Create the service structure\n",
    "./scripts/create-chat-ai-service.sh\n",
    "\n",
    "# Implement basic Express app with health endpoint\n",
    "# Add OpenAI integration\n",
    "# Add basic chat functionality\n",
    "# Test with Docker Compose\n",
    "```\n",
    "\n",
    "#### **Step 2: Extract Computer Vision Service**\n",
    "```bash\n",
    "# Copy existing computer vision code\n",
    "cp -r ../MycologyResearchPipeline/services/computer_vision.py ./computer-vision-service/\n",
    "\n",
    "# Create Flask wrapper\n",
    "# Add Docker configuration\n",
    "# Test integration with Chat AI\n",
    "```\n",
    "\n",
    "#### **Step 3: Deploy and Test**\n",
    "```bash\n",
    "# Deploy with scaled configuration\n",
    "docker-compose -f docker-compose.yml -f docker-compose.override.yml up -d\n",
    "\n",
    "# Run comprehensive tests\n",
    "./test-platform.sh\n",
    "\n",
    "# Monitor in Grafana\n",
    "open http://localhost:3200\n",
    "```\n",
    "\n",
    "### üéØ **Success Metrics**\n",
    "\n",
    "**Phase 1 Complete When:**\n",
    "- ‚úÖ Chat AI responds to mycology questions\n",
    "- ‚úÖ Computer vision analysis works via API\n",
    "- ‚úÖ Health monitoring shows all services green\n",
    "- ‚úÖ Basic integration test passes\n",
    "\n",
    "**Phase 2 Complete When:**\n",
    "- ‚úÖ Real-time notifications work\n",
    "- ‚úÖ Batch tracking creates and monitors batches\n",
    "- ‚úÖ Authentication protects all endpoints\n",
    "- ‚úÖ All services scale independently\n",
    "\n",
    "**Phase 3 Complete When:**\n",
    "- ‚úÖ Complete workflow: image ‚Üí analysis ‚Üí AI ‚Üí report\n",
    "- ‚úÖ Frontend provides unified experience\n",
    "- ‚úÖ Production deployment is stable\n",
    "- ‚úÖ Monitoring and alerts are operational\n",
    "\n",
    "### üöÄ **Ready to Start Implementation?**\n",
    "\n",
    "The architecture is complete and ready for implementation. The first priority should be the **Enhanced Chat AI Service** as it's the core integration point that connects all other services.\n",
    "\n",
    "**Would you like me to help implement the Enhanced Chat AI Service first?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc8879",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# create-chat-ai-service.sh - Bootstrap Enhanced Chat AI Service\n",
    "\n",
    "echo \"ü§ñ Creating Enhanced Chat AI Service...\"\n",
    "\n",
    "# Create service directory structure\n",
    "mkdir -p enhanced-chat-ai-service/{src/{routes,services,middleware,types,utils},tests,docker}\n",
    "\n",
    "cd enhanced-chat-ai-service\n",
    "\n",
    "# Create package.json\n",
    "cat > package.json << 'EOF'\n",
    "{\n",
    "  \"name\": \"enhanced-chat-ai-service\",\n",
    "  \"version\": \"1.0.0\",\n",
    "  \"description\": \"Multi-provider AI chat service for Unified Mycology Platform\",\n",
    "  \"main\": \"dist/app.js\",\n",
    "  \"scripts\": {\n",
    "    \"start\": \"node dist/app.js\",\n",
    "    \"dev\": \"ts-node-dev --respawn --transpile-only src/app.ts\",\n",
    "    \"build\": \"tsc\",\n",
    "    \"test\": \"jest\",\n",
    "    \"lint\": \"eslint src/**/*.ts\"\n",
    "  },\n",
    "  \"dependencies\": {\n",
    "    \"express\": \"^4.18.2\",\n",
    "    \"cors\": \"^2.8.5\",\n",
    "    \"helmet\": \"^7.0.0\",\n",
    "    \"dotenv\": \"^16.3.1\",\n",
    "    \"openai\": \"^4.20.1\",\n",
    "    \"anthropic\": \"^0.9.1\",\n",
    "    \"axios\": \"^1.6.2\",\n",
    "    \"redis\": \"^4.6.7\",\n",
    "    \"joi\": \"^17.11.0\",\n",
    "    \"jsonwebtoken\": \"^9.0.2\",\n",
    "    \"winston\": \"^3.11.0\",\n",
    "    \"express-rate-limit\": \"^7.1.5\",\n",
    "    \"multer\": \"^1.4.5-lts.1\"\n",
    "  },\n",
    "  \"devDependencies\": {\n",
    "    \"@types/express\": \"^4.17.21\",\n",
    "    \"@types/cors\": \"^2.8.15\",\n",
    "    \"@types/multer\": \"^1.4.11\",\n",
    "    \"@types/jsonwebtoken\": \"^9.0.5\",\n",
    "    \"@types/node\": \"^20.8.7\",\n",
    "    \"typescript\": \"^5.2.2\",\n",
    "    \"ts-node-dev\": \"^2.0.0\",\n",
    "    \"jest\": \"^29.7.0\",\n",
    "    \"@types/jest\": \"^29.5.8\",\n",
    "    \"eslint\": \"^8.52.0\",\n",
    "    \"@typescript-eslint/eslint-plugin\": \"^6.9.0\",\n",
    "    \"@typescript-eslint/parser\": \"^6.9.0\"\n",
    "  }\n",
    "}\n",
    "EOF\n",
    "\n",
    "# Create TypeScript configuration\n",
    "cat > tsconfig.json << 'EOF'\n",
    "{\n",
    "  \"compilerOptions\": {\n",
    "    \"target\": \"ES2020\",\n",
    "    \"module\": \"commonjs\",\n",
    "    \"lib\": [\"ES2020\"],\n",
    "    \"outDir\": \"./dist\",\n",
    "    \"rootDir\": \"./src\",\n",
    "    \"strict\": true,\n",
    "    \"esModuleInterop\": true,\n",
    "    \"skipLibCheck\": true,\n",
    "    \"forceConsistentCasingInFileNames\": true,\n",
    "    \"resolveJsonModule\": true,\n",
    "    \"declaration\": true,\n",
    "    \"declarationMap\": true,\n",
    "    \"sourceMap\": true,\n",
    "    \"removeComments\": true,\n",
    "    \"noImplicitAny\": true,\n",
    "    \"strictNullChecks\": true,\n",
    "    \"strictFunctionTypes\": true,\n",
    "    \"noImplicitReturns\": true,\n",
    "    \"noFallthroughCasesInSwitch\": true,\n",
    "    \"moduleResolution\": \"node\",\n",
    "    \"baseUrl\": \"./\",\n",
    "    \"paths\": {\n",
    "      \"@/*\": [\"src/*\"]\n",
    "    }\n",
    "  },\n",
    "  \"include\": [\"src/**/*\"],\n",
    "  \"exclude\": [\"node_modules\", \"dist\", \"tests\"]\n",
    "}\n",
    "EOF\n",
    "\n",
    "# Create main application file\n",
    "cat > src/app.ts << 'EOF'\n",
    "import express from 'express';\n",
    "import cors from 'cors';\n",
    "import helmet from 'helmet';\n",
    "import rateLimit from 'express-rate-limit';\n",
    "import dotenv from 'dotenv';\n",
    "import { errorHandler } from './middleware/errorHandler';\n",
    "import { logger } from './utils/logger';\n",
    "import chatRoutes from './routes/chat';\n",
    "import healthRoutes from './routes/health';\n",
    "\n",
    "dotenv.config();\n",
    "\n",
    "const app = express();\n",
    "const port = process.env.PORT || 3000;\n",
    "\n",
    "// Security middleware\n",
    "app.use(helmet());\n",
    "app.use(cors({\n",
    "  origin: process.env.FRONTEND_URL || 'http://localhost:3100',\n",
    "  credentials: true\n",
    "}));\n",
    "\n",
    "// Rate limiting\n",
    "const limiter = rateLimit({\n",
    "  windowMs: 15 * 60 * 1000, // 15 minutes\n",
    "  max: 100, // limit each IP to 100 requests per windowMs\n",
    "  message: 'Too many requests from this IP, please try again later.'\n",
    "});\n",
    "app.use(limiter);\n",
    "\n",
    "// Body parsing middleware\n",
    "app.use(express.json({ limit: '10mb' }));\n",
    "app.use(express.urlencoded({ extended: true, limit: '10mb' }));\n",
    "\n",
    "// Routes\n",
    "app.use('/api/chat', chatRoutes);\n",
    "app.use('/health', healthRoutes);\n",
    "\n",
    "// Error handling\n",
    "app.use(errorHandler);\n",
    "\n",
    "// Start server\n",
    "app.listen(port, () => {\n",
    "  logger.info(`Enhanced Chat AI Service running on port ${port}`);\n",
    "});\n",
    "\n",
    "export default app;\n",
    "EOF\n",
    "\n",
    "# Create health routes\n",
    "cat > src/routes/health.ts << 'EOF'\n",
    "import { Router, Request, Response } from 'express';\n",
    "import { logger } from '../utils/logger';\n",
    "\n",
    "const router = Router();\n",
    "\n",
    "router.get('/', async (req: Request, res: Response) => {\n",
    "  try {\n",
    "    const health = {\n",
    "      status: 'healthy',\n",
    "      timestamp: new Date().toISOString(),\n",
    "      uptime: process.uptime(),\n",
    "      service: 'enhanced-chat-ai-service',\n",
    "      version: '1.0.0',\n",
    "      dependencies: {\n",
    "        openai: process.env.OPENAI_API_KEY ? 'configured' : 'missing',\n",
    "        anthropic: process.env.ANTHROPIC_API_KEY ? 'configured' : 'missing',\n",
    "        redis: 'checking...' // TODO: Add Redis health check\n",
    "      }\n",
    "    };\n",
    "\n",
    "    res.status(200).json(health);\n",
    "  } catch (error) {\n",
    "    logger.error('Health check failed:', error);\n",
    "    res.status(503).json({\n",
    "      status: 'unhealthy',\n",
    "      error: 'Service health check failed'\n",
    "    });\n",
    "  }\n",
    "});\n",
    "\n",
    "export default router;\n",
    "EOF\n",
    "\n",
    "# Create basic chat routes\n",
    "cat > src/routes/chat.ts << 'EOF'\n",
    "import { Router, Request, Response } from 'express';\n",
    "import { ChatService } from '../services/ChatService';\n",
    "import { logger } from '../utils/logger';\n",
    "\n",
    "const router = Router();\n",
    "const chatService = new ChatService();\n",
    "\n",
    "router.post('/message', async (req: Request, res: Response) => {\n",
    "  try {\n",
    "    const { message, userId, sessionId } = req.body;\n",
    "    \n",
    "    if (!message || !userId) {\n",
    "      return res.status(400).json({\n",
    "        error: 'Message and userId are required'\n",
    "      });\n",
    "    }\n",
    "\n",
    "    const response = await chatService.processMessage({\n",
    "      message,\n",
    "      userId,\n",
    "      sessionId: sessionId || `session_${Date.now()}`\n",
    "    });\n",
    "\n",
    "    res.json(response);\n",
    "  } catch (error) {\n",
    "    logger.error('Chat message processing failed:', error);\n",
    "    res.status(500).json({\n",
    "      error: 'Failed to process chat message'\n",
    "    });\n",
    "  }\n",
    "});\n",
    "\n",
    "router.post('/analyze-and-chat', async (req: Request, res: Response) => {\n",
    "  try {\n",
    "    // TODO: Implement image analysis integration\n",
    "    const { message, userId, analysisType } = req.body;\n",
    "    \n",
    "    res.json({\n",
    "      message: 'Analysis and chat integration coming soon',\n",
    "      analysisType,\n",
    "      userId\n",
    "    });\n",
    "  } catch (error) {\n",
    "    logger.error('Analysis and chat failed:', error);\n",
    "    res.status(500).json({\n",
    "      error: 'Failed to process analysis and chat'\n",
    "    });\n",
    "  }\n",
    "});\n",
    "\n",
    "export default router;\n",
    "EOF\n",
    "\n",
    "# Create chat service\n",
    "cat > src/services/ChatService.ts << 'EOF'\n",
    "import OpenAI from 'openai';\n",
    "import Anthropic from 'anthropic';\n",
    "import { logger } from '../utils/logger';\n",
    "\n",
    "interface ChatMessage {\n",
    "  message: string;\n",
    "  userId: string;\n",
    "  sessionId: string;\n",
    "}\n",
    "\n",
    "interface ChatResponse {\n",
    "  response: string;\n",
    "  provider: string;\n",
    "  sessionId: string;\n",
    "  timestamp: string;\n",
    "}\n",
    "\n",
    "export class ChatService {\n",
    "  private openai: OpenAI;\n",
    "  private anthropic: Anthropic;\n",
    "\n",
    "  constructor() {\n",
    "    this.openai = new OpenAI({\n",
    "      apiKey: process.env.OPENAI_API_KEY\n",
    "    });\n",
    "    \n",
    "    this.anthropic = new Anthropic({\n",
    "      apiKey: process.env.ANTHROPIC_API_KEY\n",
    "    });\n",
    "  }\n",
    "\n",
    "  async processMessage(chatMessage: ChatMessage): Promise<ChatResponse> {\n",
    "    try {\n",
    "      // Intelligent model routing based on message content\n",
    "      const provider = this.selectProvider(chatMessage.message);\n",
    "      \n",
    "      let response: string;\n",
    "      \n",
    "      if (provider === 'openai') {\n",
    "        response = await this.callOpenAI(chatMessage.message);\n",
    "      } else {\n",
    "        response = await this.callAnthropic(chatMessage.message);\n",
    "      }\n",
    "\n",
    "      return {\n",
    "        response,\n",
    "        provider,\n",
    "        sessionId: chatMessage.sessionId,\n",
    "        timestamp: new Date().toISOString()\n",
    "      };\n",
    "    } catch (error) {\n",
    "      logger.error('Chat service error:', error);\n",
    "      throw new Error('Failed to process chat message');\n",
    "    }\n",
    "  }\n",
    "\n",
    "  private selectProvider(message: string): 'openai' | 'anthropic' {\n",
    "    // Simple routing logic - can be enhanced with more sophisticated rules\n",
    "    const analysisKeywords = ['analyze', 'identify', 'classification', 'scientific'];\n",
    "    const hasAnalysisKeywords = analysisKeywords.some(keyword => \n",
    "      message.toLowerCase().includes(keyword)\n",
    "    );\n",
    "    \n",
    "    return hasAnalysisKeywords ? 'openai' : 'anthropic';\n",
    "  }\n",
    "\n",
    "  private async callOpenAI(message: string): Promise<string> {\n",
    "    const completion = await this.openai.chat.completions.create({\n",
    "      model: 'gpt-4o',\n",
    "      messages: [\n",
    "        {\n",
    "          role: 'system',\n",
    "          content: `You are an expert mycologist and AI assistant specializing in mushroom identification, cultivation, and research. Provide accurate, scientific, and helpful responses about fungi, mycology, and related topics.`\n",
    "        },\n",
    "        {\n",
    "          role: 'user',\n",
    "          content: message\n",
    "        }\n",
    "      ],\n",
    "      temperature: 0.7,\n",
    "      max_tokens: 2000\n",
    "    });\n",
    "\n",
    "    return completion.choices[0]?.message?.content || 'No response generated';\n",
    "  }\n",
    "\n",
    "  private async callAnthropic(message: string): Promise<string> {\n",
    "    const completion = await this.anthropic.messages.create({\n",
    "      model: 'claude-3-haiku-20240307',\n",
    "      max_tokens: 2000,\n",
    "      messages: [\n",
    "        {\n",
    "          role: 'user',\n",
    "          content: `You are an expert mycologist and AI assistant. Please respond to this mycology-related question: ${message}`\n",
    "        }\n",
    "      ]\n",
    "    });\n",
    "\n",
    "    return completion.content[0]?.type === 'text' ? completion.content[0].text : 'No response generated';\n",
    "  }\n",
    "}\n",
    "EOF\n",
    "\n",
    "# Create logger utility\n",
    "cat > src/utils/logger.ts << 'EOF'\n",
    "import winston from 'winston';\n",
    "\n",
    "const logger = winston.createLogger({\n",
    "  level: process.env.LOG_LEVEL || 'info',\n",
    "  format: winston.format.combine(\n",
    "    winston.format.timestamp(),\n",
    "    winston.format.errors({ stack: true }),\n",
    "    winston.format.colorize(),\n",
    "    winston.format.simple()\n",
    "  ),\n",
    "  transports: [\n",
    "    new winston.transports.Console(),\n",
    "    new winston.transports.File({ filename: 'logs/error.log', level: 'error' }),\n",
    "    new winston.transports.File({ filename: 'logs/combined.log' })\n",
    "  ]\n",
    "});\n",
    "\n",
    "export { logger };\n",
    "EOF\n",
    "\n",
    "# Create error handler middleware\n",
    "cat > src/middleware/errorHandler.ts << 'EOF'\n",
    "import { Request, Response, NextFunction } from 'express';\n",
    "import { logger } from '../utils/logger';\n",
    "\n",
    "export const errorHandler = (\n",
    "  error: Error,\n",
    "  req: Request,\n",
    "  res: Response,\n",
    "  next: NextFunction\n",
    ") => {\n",
    "  logger.error('Error occurred:', {\n",
    "    message: error.message,\n",
    "    stack: error.stack,\n",
    "    url: req.url,\n",
    "    method: req.method\n",
    "  });\n",
    "\n",
    "  res.status(500).json({\n",
    "    error: 'Internal server error',\n",
    "    message: process.env.NODE_ENV === 'development' ? error.message : 'Something went wrong'\n",
    "  });\n",
    "};\n",
    "EOF\n",
    "\n",
    "# Create Dockerfile\n",
    "cat > Dockerfile << 'EOF'\n",
    "FROM node:18-alpine\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apk add --no-cache curl dumb-init\n",
    "\n",
    "# Create non-root user\n",
    "RUN addgroup -g 1001 -S nodejs && adduser -S nextjs -u 1001\n",
    "\n",
    "# Copy package files\n",
    "COPY package*.json ./\n",
    "COPY tsconfig.json ./\n",
    "\n",
    "# Install dependencies\n",
    "RUN npm ci --only=production && npm cache clean --force\n",
    "\n",
    "# Copy source code\n",
    "COPY . .\n",
    "\n",
    "# Build TypeScript\n",
    "RUN npm run build\n",
    "\n",
    "# Create logs directory\n",
    "RUN mkdir -p logs && chown -R nextjs:nodejs /app\n",
    "\n",
    "# Switch to non-root user\n",
    "USER nextjs\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \\\n",
    "    CMD curl -f http://localhost:3000/health || exit 1\n",
    "\n",
    "EXPOSE 3000\n",
    "\n",
    "ENTRYPOINT [\"dumb-init\", \"--\"]\n",
    "CMD [\"npm\", \"start\"]\n",
    "EOF\n",
    "\n",
    "echo \"‚úÖ Enhanced Chat AI Service structure created!\"\n",
    "echo \"üìÅ Directory: enhanced-chat-ai-service/\"\n",
    "echo \"\"\n",
    "echo \"üîÑ Next steps:\"\n",
    "echo \"1. cd enhanced-chat-ai-service\"\n",
    "echo \"2. npm install\"\n",
    "echo \"3. Copy .env.example to .env and configure API keys\"\n",
    "echo \"4. npm run dev (for development)\"\n",
    "echo \"5. docker-compose up chat-ai-service (for containerized testing)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077d454",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# setup-development-environment.sh - Set up complete development environment\n",
    "\n",
    "echo \"üîß Setting up CroweOS Microservices Development Environment...\"\n",
    "\n",
    "# Create project root structure\n",
    "mkdir -p crowe-os-microservices/{services,shared,infrastructure,documentation,tests}\n",
    "cd crowe-os-microservices\n",
    "\n",
    "# Create shared utilities\n",
    "mkdir -p shared/{types,middleware,utils,configs}\n",
    "\n",
    "# Create infrastructure setup\n",
    "mkdir -p infrastructure/{docker,nginx,monitoring,scripts}\n",
    "\n",
    "# Create environment file template\n",
    "cat > .env.example << 'EOF'\n",
    "# Database Configuration\n",
    "POSTGRES_USER=crowe_admin\n",
    "POSTGRES_PASSWORD=secure_password_here\n",
    "POSTGRES_DB=crowe_main\n",
    "POSTGRES_HOST=localhost\n",
    "POSTGRES_PORT=5432\n",
    "\n",
    "# Redis Configuration\n",
    "REDIS_HOST=localhost\n",
    "REDIS_PORT=6379\n",
    "REDIS_PASSWORD=redis_password_here\n",
    "\n",
    "# AI Service API Keys\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "ANTHROPIC_API_KEY=your_anthropic_api_key_here\n",
    "\n",
    "# Service URLs\n",
    "FRONTEND_URL=http://localhost:3100\n",
    "CHAT_AI_SERVICE_URL=http://localhost:3000\n",
    "COMPUTER_VISION_SERVICE_URL=http://localhost:3001\n",
    "HEALTH_MONITORING_SERVICE_URL=http://localhost:3002\n",
    "\n",
    "# Authentication\n",
    "JWT_SECRET=your_jwt_secret_here\n",
    "JWT_EXPIRES_IN=24h\n",
    "\n",
    "# Monitoring\n",
    "PROMETHEUS_PORT=9090\n",
    "GRAFANA_PORT=3030\n",
    "GRAFANA_ADMIN_PASSWORD=admin_password_here\n",
    "\n",
    "# File Storage\n",
    "UPLOAD_MAX_SIZE=10mb\n",
    "STORAGE_PATH=/app/storage\n",
    "\n",
    "# Logging\n",
    "LOG_LEVEL=info\n",
    "NODE_ENV=development\n",
    "EOF\n",
    "\n",
    "# Create shared TypeScript types\n",
    "cat > shared/types/index.ts << 'EOF'\n",
    "// Shared type definitions for CroweOS Microservices\n",
    "\n",
    "export interface ChatMessage {\n",
    "  id: string;\n",
    "  userId: string;\n",
    "  sessionId: string;\n",
    "  message: string;\n",
    "  timestamp: string;\n",
    "  provider?: 'openai' | 'anthropic';\n",
    "}\n",
    "\n",
    "export interface ChatResponse {\n",
    "  id: string;\n",
    "  response: string;\n",
    "  provider: string;\n",
    "  sessionId: string;\n",
    "  timestamp: string;\n",
    "  confidence?: number;\n",
    "}\n",
    "\n",
    "export interface AnalysisRequest {\n",
    "  id: string;\n",
    "  userId: string;\n",
    "  imageUrl?: string;\n",
    "  imageData?: Buffer;\n",
    "  analysisType: 'identification' | 'growth_analysis' | 'contamination_check';\n",
    "  timestamp: string;\n",
    "}\n",
    "\n",
    "export interface AnalysisResult {\n",
    "  id: string;\n",
    "  requestId: string;\n",
    "  species?: string;\n",
    "  confidence: number;\n",
    "  characteristics: string[];\n",
    "  recommendations: string[];\n",
    "  warnings?: string[];\n",
    "  timestamp: string;\n",
    "}\n",
    "\n",
    "export interface HealthStatus {\n",
    "  service: string;\n",
    "  status: 'healthy' | 'unhealthy' | 'degraded';\n",
    "  version: string;\n",
    "  uptime: number;\n",
    "  timestamp: string;\n",
    "  dependencies: Record<string, string>;\n",
    "  metrics?: {\n",
    "    cpu: number;\n",
    "    memory: number;\n",
    "    requests: number;\n",
    "  };\n",
    "}\n",
    "\n",
    "export interface ServiceResponse<T = any> {\n",
    "  success: boolean;\n",
    "  data?: T;\n",
    "  error?: string;\n",
    "  timestamp: string;\n",
    "}\n",
    "\n",
    "export interface User {\n",
    "  id: string;\n",
    "  email: string;\n",
    "  username: string;\n",
    "  role: 'admin' | 'researcher' | 'user';\n",
    "  createdAt: string;\n",
    "  lastActive: string;\n",
    "}\n",
    "\n",
    "export interface Project {\n",
    "  id: string;\n",
    "  userId: string;\n",
    "  name: string;\n",
    "  description: string;\n",
    "  species: string[];\n",
    "  status: 'planning' | 'active' | 'completed' | 'archived';\n",
    "  createdAt: string;\n",
    "  updatedAt: string;\n",
    "}\n",
    "\n",
    "export interface Batch {\n",
    "  id: string;\n",
    "  projectId: string;\n",
    "  batchNumber: string;\n",
    "  species: string;\n",
    "  substrate: string;\n",
    "  inoculationDate: string;\n",
    "  expectedHarvestDate: string;\n",
    "  status: 'inoculated' | 'colonizing' | 'fruiting' | 'harvested';\n",
    "  notes: string[];\n",
    "  images: string[];\n",
    "}\n",
    "EOF\n",
    "\n",
    "# Create shared middleware\n",
    "cat > shared/middleware/auth.ts << 'EOF'\n",
    "import jwt from 'jsonwebtoken';\n",
    "import { Request, Response, NextFunction } from 'express';\n",
    "\n",
    "export interface AuthenticatedRequest extends Request {\n",
    "  user?: {\n",
    "    id: string;\n",
    "    email: string;\n",
    "    role: string;\n",
    "  };\n",
    "}\n",
    "\n",
    "export const authenticateToken = (req: AuthenticatedRequest, res: Response, next: NextFunction) => {\n",
    "  const authHeader = req.headers['authorization'];\n",
    "  const token = authHeader && authHeader.split(' ')[1];\n",
    "\n",
    "  if (!token) {\n",
    "    return res.status(401).json({ error: 'Access token required' });\n",
    "  }\n",
    "\n",
    "  jwt.verify(token, process.env.JWT_SECRET!, (err: any, user: any) => {\n",
    "    if (err) {\n",
    "      return res.status(403).json({ error: 'Invalid or expired token' });\n",
    "    }\n",
    "    req.user = user;\n",
    "    next();\n",
    "  });\n",
    "};\n",
    "\n",
    "export const requireRole = (roles: string[]) => {\n",
    "  return (req: AuthenticatedRequest, res: Response, next: NextFunction) => {\n",
    "    if (!req.user || !roles.includes(req.user.role)) {\n",
    "      return res.status(403).json({ error: 'Insufficient permissions' });\n",
    "    }\n",
    "    next();\n",
    "  };\n",
    "};\n",
    "EOF\n",
    "\n",
    "# Create service communication utility\n",
    "cat > shared/utils/serviceClient.ts << 'EOF'\n",
    "import axios, { AxiosInstance, AxiosRequestConfig } from 'axios';\n",
    "import { ServiceResponse } from '../types';\n",
    "\n",
    "export class ServiceClient {\n",
    "  private client: AxiosInstance;\n",
    "\n",
    "  constructor(baseURL: string, timeout: number = 5000) {\n",
    "    this.client = axios.create({\n",
    "      baseURL,\n",
    "      timeout,\n",
    "      headers: {\n",
    "        'Content-Type': 'application/json',\n",
    "      },\n",
    "    });\n",
    "\n",
    "    // Request interceptor for authentication\n",
    "    this.client.interceptors.request.use((config) => {\n",
    "      const token = process.env.SERVICE_TOKEN;\n",
    "      if (token) {\n",
    "        config.headers.Authorization = `Bearer ${token}`;\n",
    "      }\n",
    "      return config;\n",
    "    });\n",
    "\n",
    "    // Response interceptor for error handling\n",
    "    this.client.interceptors.response.use(\n",
    "      (response) => response,\n",
    "      (error) => {\n",
    "        console.error('Service communication error:', error.message);\n",
    "        throw error;\n",
    "      }\n",
    "    );\n",
    "  }\n",
    "\n",
    "  async get<T>(url: string, config?: AxiosRequestConfig): Promise<ServiceResponse<T>> {\n",
    "    try {\n",
    "      const response = await this.client.get(url, config);\n",
    "      return {\n",
    "        success: true,\n",
    "        data: response.data,\n",
    "        timestamp: new Date().toISOString(),\n",
    "      };\n",
    "    } catch (error: any) {\n",
    "      return {\n",
    "        success: false,\n",
    "        error: error.message,\n",
    "        timestamp: new Date().toISOString(),\n",
    "      };\n",
    "    }\n",
    "  }\n",
    "\n",
    "  async post<T>(url: string, data?: any, config?: AxiosRequestConfig): Promise<ServiceResponse<T>> {\n",
    "    try {\n",
    "      const response = await this.client.post(url, data, config);\n",
    "      return {\n",
    "        success: true,\n",
    "        data: response.data,\n",
    "        timestamp: new Date().toISOString(),\n",
    "      };\n",
    "    } catch (error: any) {\n",
    "      return {\n",
    "        success: false,\n",
    "        error: error.message,\n",
    "        timestamp: new Date().toISOString(),\n",
    "      };\n",
    "    }\n",
    "  }\n",
    "\n",
    "  async healthCheck(): Promise<boolean> {\n",
    "    try {\n",
    "      await this.client.get('/health');\n",
    "      return true;\n",
    "    } catch {\n",
    "      return false;\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "// Pre-configured service clients\n",
    "export const chatAIClient = new ServiceClient(process.env.CHAT_AI_SERVICE_URL!);\n",
    "export const computerVisionClient = new ServiceClient(process.env.COMPUTER_VISION_SERVICE_URL!);\n",
    "export const healthMonitoringClient = new ServiceClient(process.env.HEALTH_MONITORING_SERVICE_URL!);\n",
    "EOF\n",
    "\n",
    "# Create Docker Compose override for development\n",
    "cat > docker-compose.dev.yml << 'EOF'\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  # Development overrides\n",
    "  chat-ai-service:\n",
    "    build:\n",
    "      context: ./services/enhanced-chat-ai-service\n",
    "      dockerfile: Dockerfile.dev\n",
    "    volumes:\n",
    "      - ./services/enhanced-chat-ai-service:/app\n",
    "      - /app/node_modules\n",
    "    environment:\n",
    "      - NODE_ENV=development\n",
    "    command: npm run dev\n",
    "\n",
    "  computer-vision-service:\n",
    "    volumes:\n",
    "      - ./services/computer-vision-service:/app\n",
    "    environment:\n",
    "      - FLASK_ENV=development\n",
    "      - FLASK_DEBUG=1\n",
    "\n",
    "  # Development database with persistent volume\n",
    "  postgres:\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    volumes:\n",
    "      - postgres_dev_data:/var/lib/postgresql/data\n",
    "\n",
    "  redis:\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "\n",
    "  # Development monitoring\n",
    "  prometheus:\n",
    "    ports:\n",
    "      - \"9090:9090\"\n",
    "\n",
    "  grafana:\n",
    "    ports:\n",
    "      - \"3030:3000\"\n",
    "\n",
    "volumes:\n",
    "  postgres_dev_data:\n",
    "EOF\n",
    "\n",
    "# Create package.json for project root\n",
    "cat > package.json << 'EOF'\n",
    "{\n",
    "  \"name\": \"crowe-os-microservices\",\n",
    "  \"version\": \"1.0.0\",\n",
    "  \"description\": \"Unified Mycology Platform - Microservices Architecture\",\n",
    "  \"scripts\": {\n",
    "    \"dev\": \"docker-compose -f docker-compose.yml -f docker-compose.dev.yml up --build\",\n",
    "    \"dev:services\": \"docker-compose -f docker-compose.dev.yml up\",\n",
    "    \"build\": \"docker-compose build\",\n",
    "    \"start\": \"docker-compose up\",\n",
    "    \"stop\": \"docker-compose down\",\n",
    "    \"clean\": \"docker-compose down -v --remove-orphans\",\n",
    "    \"logs\": \"docker-compose logs -f\",\n",
    "    \"test\": \"echo 'Running integration tests...' && node test-suite.js\",\n",
    "    \"health\": \"curl -f http://localhost:8080/health\",\n",
    "    \"setup\": \"./infrastructure/scripts/setup-environment.sh\"\n",
    "  },\n",
    "  \"workspaces\": [\n",
    "    \"services/*\",\n",
    "    \"shared\"\n",
    "  ],\n",
    "  \"devDependencies\": {\n",
    "    \"concurrently\": \"^8.2.2\",\n",
    "    \"cross-env\": \"^7.0.3\"\n",
    "  }\n",
    "}\n",
    "EOF\n",
    "\n",
    "echo \"‚úÖ Development environment structure created!\"\n",
    "echo \"\"\n",
    "echo \"üìÇ Project Structure:\"\n",
    "echo \"   crowe-os-microservices/\"\n",
    "echo \"   ‚îú‚îÄ‚îÄ services/          # Individual microservices\"\n",
    "echo \"   ‚îú‚îÄ‚îÄ shared/            # Shared types, middleware, utilities\"\n",
    "echo \"   ‚îú‚îÄ‚îÄ infrastructure/    # Docker, Nginx, monitoring configs\"\n",
    "echo \"   ‚îú‚îÄ‚îÄ documentation/     # API docs, guides\"\n",
    "echo \"   ‚îú‚îÄ‚îÄ tests/            # Integration tests\"\n",
    "echo \"   ‚îú‚îÄ‚îÄ docker-compose.yml        # Production config\"\n",
    "echo \"   ‚îú‚îÄ‚îÄ docker-compose.dev.yml    # Development overrides\"\n",
    "echo \"   ‚îî‚îÄ‚îÄ .env.example              # Environment template\"\n",
    "echo \"\"\n",
    "echo \"üîÑ Next steps:\"\n",
    "echo \"1. Copy .env.example to .env and configure your API keys\"\n",
    "echo \"2. Run the chat service creation script above\"\n",
    "echo \"3. npm run dev (starts all services in development mode)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcbdd5",
   "metadata": {},
   "source": [
    "## üéØ Immediate Implementation Plan\n",
    "\n",
    "Based on your complete Docker Compose configuration and production setup, here's exactly what we need to implement next:\n",
    "\n",
    "### Phase 1: Core Infrastructure (Priority 1) üî•\n",
    "**Timeline: 1-2 days**\n",
    "\n",
    "1. **Enhanced Chat AI Service** (Node.js/TypeScript)\n",
    "   - ‚úÖ Service structure created above\n",
    "   - üîÑ Multi-provider AI routing (OpenAI + Anthropic)\n",
    "   - üîÑ Mycology expertise system prompts\n",
    "   - üîÑ Integration with Computer Vision service\n",
    "   - üîÑ Session management and conversation history\n",
    "\n",
    "2. **Computer Vision Service Extraction** (Python/Flask)\n",
    "   - üîÑ Extract from existing research pipeline\n",
    "   - üîÑ Containerize with proper API endpoints\n",
    "   - üîÑ Species identification models\n",
    "   - üîÑ Growth stage analysis\n",
    "   - üîÑ Contamination detection\n",
    "\n",
    "3. **Health Monitoring Service** (Node.js/TypeScript)\n",
    "   - üîÑ Service health aggregation\n",
    "   - üîÑ Performance metrics collection\n",
    "   - üîÑ Alert system integration\n",
    "   - üîÑ Dashboard API endpoints\n",
    "\n",
    "### Phase 2: Supporting Services (Priority 2) ‚ö°\n",
    "**Timeline: 2-3 days**\n",
    "\n",
    "4. **Notifications Service** (Node.js/TypeScript)\n",
    "   - üîÑ Real-time alerts\n",
    "   - üîÑ Email/SMS integration\n",
    "   - üîÑ Batch status updates\n",
    "   - üîÑ Research milestone notifications\n",
    "\n",
    "5. **Batch Tracking Service** (Node.js/TypeScript)\n",
    "   - üîÑ Growth cycle monitoring\n",
    "   - üîÑ Environmental data logging\n",
    "   - üîÑ Harvest predictions\n",
    "   - üîÑ Quality control metrics\n",
    "\n",
    "### Phase 3: Integration & Production (Priority 3) üöÄ\n",
    "**Timeline: 1-2 days**\n",
    "\n",
    "6. **Service Integration**\n",
    "   - üîÑ Inter-service communication\n",
    "   - üîÑ API Gateway routing validation\n",
    "   - üîÑ Authentication flow\n",
    "   - üîÑ Error handling and resilience\n",
    "\n",
    "7. **Production Deployment**\n",
    "   - ‚úÖ Docker Compose configuration complete\n",
    "   - üîÑ Environment configuration\n",
    "   - üîÑ SSL/TLS setup\n",
    "   - üîÑ Monitoring stack deployment\n",
    "\n",
    "### üöÄ Start Here - Next Action Items:\n",
    "\n",
    "1. **Run the Chat AI Service creation script** (provided above)\n",
    "2. **Set up your development environment** with the environment script\n",
    "3. **Configure your .env file** with API keys\n",
    "4. **Test the basic Chat AI service** with Docker Compose\n",
    "\n",
    "### üîß Ready-to-Run Commands:\n",
    "\n",
    "```bash\n",
    "# 1. Create the Enhanced Chat AI Service\n",
    "bash create-chat-ai-service.sh\n",
    "\n",
    "# 2. Set up development environment\n",
    "bash setup-development-environment.sh\n",
    "\n",
    "# 3. Start development services\n",
    "cd crowe-os-microservices\n",
    "cp .env.example .env\n",
    "# Edit .env with your API keys\n",
    "npm run dev\n",
    "```\n",
    "\n",
    "### üìä Success Metrics:\n",
    "- ‚úÖ Chat AI service responds to basic queries\n",
    "- ‚úÖ Health endpoints return 200 status\n",
    "- ‚úÖ Docker Compose brings up all services\n",
    "- ‚úÖ Nginx routes requests correctly\n",
    "- ‚úÖ Monitoring stack shows service metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
